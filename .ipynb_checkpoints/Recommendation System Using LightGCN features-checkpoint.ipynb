{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rWkNAZvtNQ6R"
   },
   "source": [
    "# Recommending Books using LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxoenua1-u5r",
    "outputId": "2718b918-3398-4e59-d95f-f028db2a5cb1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, Tensor\n",
    "import torch.sparse as sparse\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn import LGConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.version.cuda)         # Should print the CUDA version PyTorch is built with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10429/1876496731.py:15: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  items_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv('data/BX-Users.csv', sep=';', encoding='latin-1')\n",
    "# rename 'Location' and 'Age' to lowercase\n",
    "users_df.rename(columns={'Location': 'location', 'Age': 'age'}, inplace=True)\n",
    "# Example age bins\n",
    "bins = [0, 18, 35, 55, 75, float('inf')]\n",
    "labels = ['0-18', '19-35', '36-55', '56-75', '76+']\n",
    "\n",
    "users_df['age'].fillna(users_df['age'].median(), inplace=True)\n",
    "\n",
    "users_df['age_group'] = pd.cut(users_df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# rename 'User-ID' to 'user_id' \n",
    "users_df.rename(columns={'User-ID': 'user_id'}, inplace=True)\n",
    "\n",
    "items_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "# rename 'Book-Title' to 'title', 'Book-Author' to 'author'\n",
    "items_df.rename(columns={'Book-Title': 'title', 'Book-Author': 'author'}, inplace=True)\n",
    "# rename 'ISBN' to 'item_id'\n",
    "items_df.rename(columns={'ISBN': 'item_id'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                            location   age age_group\n",
       "0        1                  nyc, new york, usa  32.0     19-35\n",
       "1        2           stockton, california, usa  18.0     19-35\n",
       "2        3     moscow, yukon territory, russia  32.0     19-35\n",
       "3        4           porto, v.n.gaia, portugal  17.0      0-18\n",
       "4        5  farnborough, hants, united kingdom  32.0     19-35"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df['author'] = items_df['author'].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                0\n",
       "title                  0\n",
       "author                 0\n",
       "Year-Of-Publication    0\n",
       "Publisher              2\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with missing values\n",
    "# items_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 8)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     item_id  rating\n",
       "0   276725  034545104X       0\n",
       "1   276726  0155061224       5\n",
       "2   276727  0446520802       0\n",
       "3   276729  052165615X       3\n",
       "4   276729  0521795028       6"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding='latin-1')  \n",
    "# rename 'User-ID' to 'user_id', 'Book-Rating' to 'rating', 'ISBN' to 'item_id'\n",
    "ratings_df.rename(columns={'User-ID': 'user_id', 'Book-Rating': 'rating', 'ISBN': 'item_id'}, inplace=True)\n",
    "ratings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031136, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing\n",
    "ratings_df = ratings_df.loc[ratings_df['item_id'].isin(items_df['item_id'].unique()) & ratings_df['user_id'].isin(users_df['user_id'].unique())]\n",
    "\n",
    "print(ratings_df.shape)\n",
    "# # Keep the 100k highest ratings\n",
    "ratings_df = ratings_df[ratings_df['rating'] >= 8].iloc[:100000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsert users_df where user_id is in ratings_df\n",
    "users_df = users_df[users_df['user_id'].isin(ratings_df['user_id'].unique())].copy()\n",
    "# subsert items_df where item_id is in ratings_df\n",
    "items_df = items_df[items_df['item_id'].isin(ratings_df['item_id'].unique())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19694, 4)\n",
      "(56948, 8)\n"
     ]
    }
   ],
   "source": [
    "print(users_df.shape)\n",
    "print(items_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "user_mapping = {userid: i for i, userid in enumerate(users_df['user_id'].unique())}\n",
    "item_mapping = {isbn: i for i, isbn in enumerate(items_df['item_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mapping[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19694 entries, 11 to 278853\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   user_id    19694 non-null  int64   \n",
      " 1   location   19694 non-null  object  \n",
      " 2   age        19694 non-null  float64 \n",
      " 3   age_group  19694 non-null  category\n",
      " 4   user_idx   19694 non-null  int64   \n",
      "dtypes: category(1), float64(1), int64(2), object(1)\n",
      "memory usage: 788.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Count users and items\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "num_total = num_users + num_items\n",
    "\n",
    "# Map user and item indices\n",
    "users_df['user_idx'] = users_df['user_id'].map(user_mapping)\n",
    "items_df['item_idx'] = items_df['item_id'].map(item_mapping)\n",
    "ratings_df['user_idx'] = ratings_df['user_id'].map(user_mapping)\n",
    "ratings_df['item_idx'] = ratings_df['item_id'].map(item_mapping)\n",
    "\n",
    "# Merge the user and item features with the ratings\n",
    "# merged_df = ratings_df.merge(users_df, on='user_id').merge(items_df, on='item_id')\n",
    "\n",
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.item_idx.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "5  0399135782                             The Kitchen God's Wife   \n",
       "6  0425176428  What If?: The World's Foremost Military Histor...   \n",
       "\n",
       "                 author Year-Of-Publication                 Publisher  \\\n",
       "1  Richard Bruce Wright                2001     HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991           HarperPerennial   \n",
       "3      Gina Bari Kolata                1999      Farrar Straus Giroux   \n",
       "5               Amy Tan                1991          Putnam Pub Group   \n",
       "6         Robert Cowley                2000  Berkley Publishing Group   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...   \n",
       "\n",
       "                                         Image-URL-L  item_idx  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...         0  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...         1  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...         2  \n",
       "5  http://images.amazon.com/images/P/0399135782.0...         3  \n",
       "6  http://images.amazon.com/images/P/0425176428.0...         4  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset: transforming the user features and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                0\n",
       "title                  0\n",
       "author                 0\n",
       "Year-Of-Publication    0\n",
       "Publisher              2\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            0\n",
       "item_idx               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill missing values of locations, age_group, subject, author with 'unknown'\n",
    "def fillna_category(df, column):\n",
    "    df[column] = df[column].astype('category')\n",
    "    df[column].cat.add_categories('unknown')\n",
    "    df[column].fillna('unknown', inplace=True)\n",
    "\n",
    "# check if there are any missing values\n",
    "items_df.isna().sum()\n",
    "\n",
    "# delete rows with missing values in 'title' and 'author'\n",
    "# items_df.dropna(subset=['title', 'author'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to map categories to indices\n",
    "def map_categories(df, column):\n",
    "    unique_values = df[column].unique()\n",
    "    value_to_idx = {value: idx for idx, value in enumerate(unique_values)}\n",
    "    return df[column].map(value_to_idx), len(unique_values)\n",
    "\n",
    "# Map each categorical feature\n",
    "users_df['location_idx'], num_locations = map_categories(users_df, 'location')\n",
    "users_df['age_group_idx'], num_age_groups = map_categories(users_df, 'age_group')\n",
    "items_df['subject_idx'], num_subjects = map_categories(items_df, 'title')\n",
    "items_df['author_idx'], num_authors = map_categories(items_df, 'author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Input data for the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indices to tensors\n",
    "user_location_indices = torch.tensor(users_df['location_idx'].values, dtype=torch.long)\n",
    "user_age_group_indices = torch.tensor(users_df['age_group_idx'].values, dtype=torch.long)\n",
    "item_subject_indices = torch.tensor(items_df['subject_idx'].values, dtype=torch.long)\n",
    "item_author_indices = torch.tensor(items_df['author_idx'].values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Edge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Tensors for user and item indices\n",
    "# user_indices = torch.tensor(merged_df['user_idx'].values, dtype=torch.long)\n",
    "# item_indices = torch.tensor(merged_df['item_idx'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "# # Tensor for ratings\n",
    "# ratings = torch.tensor(merged_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# # ratings = torch.tensor(merged_df['rating'].values, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>location_idx</th>\n",
       "      <th>age_group_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>fort bragg, california, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>albuquerque, new mexico, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>bellevue, washington, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>cary, north carolina, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                      location   age age_group  user_idx  \\\n",
       "11       12   fort bragg, california, usa  32.0     19-35         0   \n",
       "15       16  albuquerque, new mexico, usa  32.0     19-35         1   \n",
       "25       26     bellevue, washington, usa  32.0     19-35         2   \n",
       "31       32         portland, oregon, usa  32.0     19-35         3   \n",
       "38       39     cary, north carolina, usa  32.0     19-35         4   \n",
       "\n",
       "    location_idx age_group_idx  \n",
       "11             0             0  \n",
       "15             1             0  \n",
       "25             2             0  \n",
       "31             3             0  \n",
       "38             4             0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>item_idx</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>author_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "5  0399135782                             The Kitchen God's Wife   \n",
       "6  0425176428  What If?: The World's Foremost Military Histor...   \n",
       "\n",
       "                 author Year-Of-Publication                 Publisher  \\\n",
       "1  Richard Bruce Wright                2001     HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991           HarperPerennial   \n",
       "3      Gina Bari Kolata                1999      Farrar Straus Giroux   \n",
       "5               Amy Tan                1991          Putnam Pub Group   \n",
       "6         Robert Cowley                2000  Berkley Publishing Group   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...   \n",
       "\n",
       "                                         Image-URL-L  item_idx  subject_idx  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...         0            0   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...         1            1   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...         2            2   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...         3            3   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...         4            4   \n",
       "\n",
       "   author_idx  \n",
       "1           0  \n",
       "2           1  \n",
       "3           2  \n",
       "5           3  \n",
       "6           4  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>276747</td>\n",
       "      <td>0060517794</td>\n",
       "      <td>9</td>\n",
       "      <td>19324</td>\n",
       "      <td>3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>276747</td>\n",
       "      <td>0671537458</td>\n",
       "      <td>9</td>\n",
       "      <td>19324</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>276747</td>\n",
       "      <td>0679776818</td>\n",
       "      <td>8</td>\n",
       "      <td>19324</td>\n",
       "      <td>4053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>276751</td>\n",
       "      <td>3596218098</td>\n",
       "      <td>8</td>\n",
       "      <td>19325</td>\n",
       "      <td>18749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>276754</td>\n",
       "      <td>0684867621</td>\n",
       "      <td>8</td>\n",
       "      <td>19326</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     item_id  rating  user_idx  item_idx\n",
       "16   276747  0060517794       9     19324      3147\n",
       "19   276747  0671537458       9     19324      1258\n",
       "20   276747  0679776818       8     19324      4053\n",
       "27   276751  3596218098       8     19325     18749\n",
       "28   276754  0684867621       8     19326      1346"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56947"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.item_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in ratings_df, exclude rows with item_idx < 0\n",
    "ratings_df = ratings_df[ratings_df['item_idx'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 s  14.8 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def create_adjacency_matrix(users_df, items_df, ratings_df):\n",
    "    # Basic data validation\n",
    "    if not all(col in users_df.columns for col in ['user_idx']) or \\\n",
    "       not all(col in items_df.columns for col in ['item_idx']) or \\\n",
    "       not all(col in ratings_df.columns for col in ['user_idx', 'item_idx']):\n",
    "        raise ValueError(\"Dataframes do not have the required columns\")\n",
    "\n",
    "    num_users = users_df['user_idx'].nunique()\n",
    "    num_items = items_df['item_idx'].nunique()\n",
    "\n",
    "    # Convert indices to tensor-friendly format\n",
    "    user_ids = ratings_df['user_idx'].values.astype(np.int64)\n",
    "    item_ids = ratings_df['item_idx'].values.astype(np.int64) + num_users\n",
    "\n",
    "    # Create edge index tensors\n",
    "    start_idx = torch.LongTensor([user_ids, item_ids])\n",
    "    end_idx = torch.LongTensor([item_ids, user_ids])\n",
    "\n",
    "    # Create values tensor\n",
    "    values = torch.FloatTensor([1] * 2 * len(ratings_df))\n",
    "\n",
    "    # Construct sparse adjacency matrix\n",
    "    adj_matrix = torch.sparse.FloatTensor(torch.cat([start_idx, end_idx], dim=1), values, torch.Size([num_users + num_items, num_users + num_items]))\n",
    "\n",
    "    # Normalize adjacency matrix\n",
    "    # Computing degree (sum of edges for each node)\n",
    "    deg = torch.sparse.sum(adj_matrix, dim=1).to_dense()\n",
    "\n",
    "    # Efficient normalization for user rows\n",
    "    indices = adj_matrix._indices()\n",
    "    values = adj_matrix._values()\n",
    "\n",
    "    for i in range(indices.size(1)):\n",
    "        row = indices[0, i]\n",
    "        if row < num_users:  # Normalize only user rows\n",
    "            values[i] /= deg[row]\n",
    "\n",
    "    # Reconstruct normalized adjacency matrix\n",
    "    norm_adj = torch.sparse.FloatTensor(indices, values, adj_matrix.size())\n",
    "\n",
    "    return norm_adj\n",
    "\n",
    "# Example usage\n",
    "adj_matrix = create_adjacency_matrix(users_df, items_df, ratings_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the train-validtion-test adj matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def split_sparse_tensor(adj_matrix, train_ratio=0.8, val_ratio=0.1):\n",
    "    # Extract the total number of users and items from the dimensions of the adjacency matrix\n",
    "    total_nodes = adj_matrix.size(0)\n",
    "    num_users = torch.max(adj_matrix._indices()[0]).item() + 1\n",
    "    num_items = total_nodes - num_users\n",
    "\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "\n",
    "    for user in range(num_users):\n",
    "        # Filter items for this user\n",
    "        user_mask = adj_matrix._indices()[0] == user\n",
    "        user_items = adj_matrix._indices()[1][user_mask] - num_users  # Adjust item index\n",
    "\n",
    "        # Shuffle items\n",
    "        shuffled_indices = torch.randperm(user_items.size(0))\n",
    "        user_items = user_items[shuffled_indices]\n",
    "\n",
    "        # Split items\n",
    "        num_train = int(user_items.size(0) * train_ratio)\n",
    "        num_val = int(user_items.size(0) * val_ratio)\n",
    "\n",
    "        train_items = user_items[:num_train]\n",
    "        val_items = user_items[num_train:num_train + num_val]\n",
    "        test_items = user_items[num_train + num_val:]\n",
    "\n",
    "        # Add to indices lists\n",
    "        train_indices.append(torch.stack([torch.full_like(train_items, user), train_items + num_users], dim=0))\n",
    "        val_indices.append(torch.stack([torch.full_like(val_items, user), val_items + num_users], dim=0))\n",
    "        test_indices.append(torch.stack([torch.full_like(test_items, user), test_items + num_users], dim=0))\n",
    "\n",
    "    def create_sparse_tensor(indices_list):\n",
    "        all_indices = torch.cat(indices_list, dim=1)\n",
    "        values = torch.ones(all_indices.size(1))\n",
    "        return torch.sparse.FloatTensor(all_indices, values, adj_matrix.size())\n",
    "\n",
    "    train_adj_matrix = create_sparse_tensor(train_indices)\n",
    "    val_adj_matrix = create_sparse_tensor(val_indices)\n",
    "    test_adj_matrix = create_sparse_tensor(test_indices)\n",
    "\n",
    "    return train_adj_matrix, val_adj_matrix, test_adj_matrix\n",
    "\n",
    "# Example usage\n",
    "train_adj_matrix, val_adj_matrix, test_adj_matrix = split_sparse_tensor(adj_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     1,     2,  ..., 76639, 76640, 76641],\n",
       "                       [19704, 19706, 19712,  ..., 19222, 19222, 18920]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       size=(76642, 76642), nnz=86678, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56948, 11)\n",
      "56948\n"
     ]
    }
   ],
   "source": [
    "print(items_df.shape)\n",
    "print(items_df.item_idx.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataLoader:\n",
    "    def __init__(self, adj_matrix, users_df, items_df, num_negatives=1, batch_size=1024, device='cpu'):\n",
    "        self.adj_matrix = adj_matrix.to(device)\n",
    "        self.num_negatives = num_negatives\n",
    "        self.batch_size = batch_size\n",
    "        self.num_users = users_df['user_idx'].nunique()\n",
    "        self.num_items = items_df['item_idx'].nunique()\n",
    "        self.device = device\n",
    "        self.negatives = self.precompute_negatives()\n",
    "\n",
    "    def precompute_negatives(self):\n",
    "        negatives = {}\n",
    "        for user in range(self.num_users):\n",
    "            user_row = self.adj_matrix[user].coalesce()\n",
    "            if user_row._nnz() > 0:\n",
    "                pos_items = user_row.indices()[0].cpu().numpy()\n",
    "                neg_items = np.setdiff1d(np.arange(self.num_items), pos_items)\n",
    "                negatives[user] = neg_items\n",
    "            else:\n",
    "                negatives[user] = np.arange(self.num_items)\n",
    "        return negatives\n",
    "\n",
    "    def generate_batch(self):\n",
    "        for batch_start in range(0, self.num_users, self.batch_size):\n",
    "            batch_users, batch_pos_items, batch_neg_items = [], [], []\n",
    "\n",
    "            for user in range(batch_start, min(batch_start + self.batch_size, self.num_users)):\n",
    "                user_row = self.adj_matrix[user].coalesce()\n",
    "                pos_items = user_row.indices()[0].cpu().numpy() if user_row._nnz() > 0 else np.array([])\n",
    "\n",
    "                if len(pos_items) > 0:\n",
    "                    pos_item = np.random.choice(pos_items)\n",
    "                else:\n",
    "                    pos_item = np.random.randint(0, self.num_items)  # Fallback if no positive items\n",
    "\n",
    "                # Adjust the number of negatives based on available samples\n",
    "                num_available_negs = len(self.negatives[user])\n",
    "                num_negatives = min(self.num_negatives, num_available_negs)\n",
    "\n",
    "                # If less negatives are available, allow repetition\n",
    "                neg_samples = np.random.choice(self.negatives[user], num_negatives, replace=num_negatives < self.num_negatives)\n",
    "\n",
    "                for neg_sample in neg_samples:\n",
    "                    batch_users.append(user)\n",
    "                    batch_pos_items.append(pos_item)\n",
    "                    batch_neg_items.append(neg_sample)\n",
    "                    \n",
    "                \n",
    "                # Add a check to ensure equal lengths\n",
    "                assert len(batch_pos_items) == len(batch_neg_items), \"Mismatch in batch sizes of positives and negatives during batch generation\"\n",
    "                                      \n",
    "            if batch_users:\n",
    "                  # print(f\"Generated batch sizes - Users: {len(batch_users)}, Pos: {len(batch_pos_items)}, Neg: {len(batch_neg_items)}\")\n",
    "                  yield torch.tensor(batch_users, dtype=torch.long, device=self.device), \\\n",
    "                      torch.tensor(batch_pos_items, dtype=torch.long, device=self.device), \\\n",
    "                      torch.tensor(batch_neg_items, dtype=torch.long, device=self.device)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_adj_matrix, val_adj_matrix, test_adj_matrix = split_adj_matrix(adj_matrix)\n",
    "train_loader = GraphDataLoader(train_adj_matrix, users_df, items_df, num_negatives=1, batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JOB5kDmtUrUY"
   },
   "source": [
    "## Implementing the LightGCN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.sparse import mm as sparse_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.sparse import mm as sparse_mm\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, num_layers):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Initialization\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "\n",
    "    def forward(self, user_indices, item_indices, adj_matrix):\n",
    "        # Initial batch size check\n",
    "        initial_batch_size = user_indices.size(0)\n",
    "        assert initial_batch_size == item_indices.size(0), \"Initial batch sizes of user and item indices must be equal\"\n",
    "\n",
    "        # Check and filter out-of-range indices\n",
    "        valid_user_mask = (user_indices >= 0) & (user_indices < self.num_users)\n",
    "        valid_item_mask = (item_indices >= 0) & (item_indices < self.num_items)\n",
    "        valid_indices_mask = valid_user_mask & valid_item_mask\n",
    "\n",
    "        # Filter based on the mask\n",
    "        user_indices = user_indices[valid_indices_mask]\n",
    "        item_indices = item_indices[valid_indices_mask]\n",
    "\n",
    "        # Handling case where all indices are invalid\n",
    "        if len(user_indices) == 0 or len(item_indices) == 0:\n",
    "            return torch.zeros(initial_batch_size)\n",
    "\n",
    "        # Create initial embeddings\n",
    "        all_embeddings = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
    "\n",
    "        # List to hold all embeddings for each layer\n",
    "        all_user_embs = [self.user_embedding(user_indices)]\n",
    "        all_item_embs = [self.item_embedding(item_indices)]\n",
    "\n",
    "        # Perform graph convolutions\n",
    "        for _ in range(self.num_layers):\n",
    "            all_embeddings = sparse_mm(adj_matrix, all_embeddings)\n",
    "\n",
    "            user_emb = all_embeddings[:self.num_users]\n",
    "            item_emb = all_embeddings[self.num_users:]\n",
    "\n",
    "            all_user_embs.append(user_emb[user_indices])\n",
    "            all_item_embs.append(item_emb[item_indices])\n",
    "\n",
    "        # Compute final embeddings as the mean of all layers' embeddings\n",
    "        final_user_emb = torch.mean(torch.stack(all_user_embs), dim=0)\n",
    "        final_item_emb = torch.mean(torch.stack(all_item_embs), dim=0)\n",
    "\n",
    "        # Predict ratings by computing the dot product of user and item embeddings\n",
    "        scores = torch.sum(final_user_emb * final_item_emb, dim=1)\n",
    "\n",
    "        # Ensuring output scores match the initial batch size\n",
    "        if scores.size(0) != initial_batch_size:\n",
    "            # Padding scores to match initial batch size\n",
    "            padded_scores = torch.zeros(initial_batch_size)\n",
    "            padded_scores[:scores.size(0)] = scores\n",
    "            return padded_scores\n",
    "\n",
    "        return scores\n",
    "\n",
    "# Example usage:\n",
    "# model = LightGCN(num_users=1000, num_items=500, embedding_dim=64, num_layers=3)\n",
    "# ... (setup data and training loop) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(targets, predictions, k=10):\n",
    "    top_k_preds = predictions.topk(k, dim=1).indices\n",
    "    relevant = targets.gather(1, top_k_preds)\n",
    "    precision = relevant.sum().float() / (k * targets.size(0))\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(targets, predictions, k=10):\n",
    "    top_k_preds = predictions.topk(k, dim=1).indices\n",
    "    relevant = targets.gather(1, top_k_preds)\n",
    "    recall = relevant.sum().float() / targets.sum()\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# BPR Loss\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    if pos_scores.shape != neg_scores.shape:\n",
    "        raise ValueError(f\"pos_scores and neg_scores must be of the same shape, got {pos_scores.shape} and {neg_scores.shape}\")\n",
    "    \n",
    "    return -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_adj_matrix, val_adj_matrix, test_adj_matrix = split_adj_matrix(adj_matrix)\n",
    "train_loader = GraphDataLoader(train_adj_matrix, users_df, items_df, num_negatives=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = GraphDataLoader(val_adj_matrix, users_df, items_df, num_negatives=1, batch_size=128)\n",
    "test_loader = GraphDataLoader(test_adj_matrix, users_df, items_df, num_negatives=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, epochs, optimizer, loss_fn, adj_matrix, early_stopping_rounds=5, device='cuda'):\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_epochs = 0\n",
    "\n",
    "    # Move the model to the specified device\n",
    "    model.to(device)\n",
    "    adj_matrix = adj_matrix.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        num_train_batches = 0\n",
    "\n",
    "        for users, pos_items, neg_items in train_loader.generate_batch():\n",
    "            # Add a check here to ensure consistent batch sizes\n",
    "            assert pos_items.shape == neg_items.shape, \"Mismatch in shapes of pos_items and neg_items during training\"\n",
    "\n",
    "            # Move tensors to the specified device\n",
    "            users = users.to(device)\n",
    "            pos_items = pos_items.to(device)\n",
    "            neg_items = neg_items.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            pos_scores = model(users, pos_items, adj_matrix)\n",
    "            neg_scores = model(users, neg_items, adj_matrix)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(pos_scores, neg_scores)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "\n",
    "        avg_train_loss = total_train_loss / num_train_batches if num_train_batches > 0 else 0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {avg_train_loss:.4f}\", end='')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        num_val_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for users, pos_items, neg_items in val_loader.generate_batch():\n",
    "                # Move tensors to the specified device\n",
    "                users = users.to(device)\n",
    "                pos_items = pos_items.to(device)\n",
    "                neg_items = neg_items.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                pos_scores = model(users, pos_items, adj_matrix)\n",
    "                neg_scores = model(users, neg_items, adj_matrix)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_fn(pos_scores, neg_scores)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "                num_val_batches += 1\n",
    "\n",
    "        avg_val_loss = total_val_loss / num_val_batches if num_val_batches > 0 else 0\n",
    "        print(f\" - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            no_improvement_epochs = 0\n",
    "            torch.save(model.state_dict(), 'models/best_model.pth')  # Save the best model\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "            if no_improvement_epochs >= early_stopping_rounds:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                break\n",
    "\n",
    "# Example usage\n",
    "# model = YourModel(...)\n",
    "# train_loader = YourDataLoader(...)\n",
    "# val_loader = YourDataLoader(...)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), ...)\n",
    "# loss_fn = your_loss_function\n",
    "# adj_matrix = your_adjacency_matrix\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# train_and_validate(model, train_loader, val_loader, epochs, optimizer, loss_fn, adj_matrix, early_stopping_rounds=5, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training Loss: 0.7003 - Validation Loss: 0.7025\n",
      "Epoch 2/10 - Training Loss: 0.7007 - Validation Loss: 0.7017\n",
      "Epoch 3/10 - Training Loss: 0.7001 - Validation Loss: inf\n",
      "Epoch 4/10 - Training Loss: 0.6966 - Validation Loss: 0.7018\n",
      "Epoch 5/10 - Training Loss: 0.7008 - Validation Loss: 0.6998\n",
      "Epoch 6/10 - Training Loss: 0.6997 - Validation Loss: 0.7038\n",
      "Epoch 7/10 - Training Loss: 0.6938 - Validation Loss: 0.7037\n",
      "Epoch 8/10 - Training Loss: 0.6945 - Validation Loss: 0.7054\n",
      "Epoch 9/10 - Training Loss: 0.6950 - Validation Loss: 0.7016\n",
      "Epoch 10/10 - Training Loss: 0.6934 - Validation Loss: 0.7063\n",
      "Early stopping triggered after 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "# Define the model and optimizer with L2 regularization\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LightGCN(num_users, num_items, embedding_dim=64, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "loss_fn = bpr_loss\n",
    "adj_matrix = adj_matrix.to(device)\n",
    "# Corrected function call\n",
    "train_and_validate(model, train_loader, val_loader, 10, optimizer, loss_fn, adj_matrix, early_stopping_rounds=5, device=device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def precision_at_k(targets, predictions, k=10):\n",
    "    k = min(k, predictions.size(1))  # Adjust k to the size of predictions if needed\n",
    "    top_k_preds = predictions.topk(k, dim=1).indices\n",
    "    relevant = targets.gather(1, top_k_preds)\n",
    "    precision = relevant.sum().float() / (k * targets.size(0))\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(targets, predictions, k=10):\n",
    "    k = min(k, predictions.size(1))  # Adjust k to the size of predictions if needed\n",
    "    top_k_preds = predictions.topk(k, dim=1).indices\n",
    "    relevant = targets.gather(1, top_k_preds)\n",
    "    recall = relevant.sum().float() / targets.sum()\n",
    "    return recall\n",
    "\n",
    "def test_model(model, test_loader, adj_matrix, k=10, device='cuda'):\n",
    "    model.to(device)\n",
    "    adj_matrix = adj_matrix.to(device)\n",
    "\n",
    "    # Metrics\n",
    "    total_precision = 0.0\n",
    "    total_recall = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for users, pos_items, neg_items in test_loader.generate_batch():\n",
    "            users = users.to(device)\n",
    "            pos_items = pos_items.to(device)\n",
    "            neg_items = neg_items.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            pos_scores = model(users, pos_items, adj_matrix)\n",
    "            neg_scores = model(users, neg_items, adj_matrix)\n",
    "\n",
    "            # Ensure pos_scores and neg_scores are 2D before concatenation\n",
    "            if pos_scores.dim() == 1:\n",
    "                pos_scores = pos_scores.unsqueeze(1)\n",
    "            if neg_scores.dim() == 1:\n",
    "                neg_scores = neg_scores.unsqueeze(1)\n",
    "\n",
    "            # Combine scores and sort them\n",
    "            all_scores = torch.cat([pos_scores, neg_scores], dim=1)\n",
    "            sorted_scores, sorted_indices = torch.sort(all_scores, dim=1, descending=True)\n",
    "\n",
    "            # Ensure all_scores is 2D before creating targets\n",
    "            if all_scores.dim() == 1:\n",
    "                all_scores = all_scores.unsqueeze(1)\n",
    "\n",
    "            # Generate 'targets' tensor\n",
    "            targets = torch.zeros_like(all_scores)\n",
    "            num_positives = pos_items.size(1) if pos_items.dim() > 1 else 1\n",
    "            targets[:, :num_positives] = 1  # Marking the first 'n' items as positives\n",
    "\n",
    "            # Adjust k based on the number of items\n",
    "            k_adjusted = min(k, all_scores.size(1))\n",
    "\n",
    "            # Compute precision and recall\n",
    "            precision = precision_at_k(targets, sorted_scores, k=k_adjusted)\n",
    "            recall = recall_at_k(targets, sorted_scores, k=k_adjusted)\n",
    "\n",
    "            total_precision += precision.item()\n",
    "            total_recall += recall.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_precision = total_precision / num_batches\n",
    "    avg_recall = total_recall / num_batches\n",
    "\n",
    "    print(f\"Test Results - Precision@{k}: {avg_precision:.4f}, Recall@{k}: {avg_recall:.4f}\")\n",
    "    return avg_precision, avg_recall\n",
    "\n",
    "# Example usage:\n",
    "# model = YourTrainedModel(...)\n",
    "# test_loader = YourDataLoader(...)\n",
    "# adj_matrix = YourAdjacencyMatrix(...)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# test_model(model, test_loader, adj_matrix, k=10, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "G6UjCTMQ_N5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - Precision@10: 0.5000, Recall@10: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader, adj_matrix, k=10, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "At4zWPfaVW6q"
   },
   "source": [
    "## Recommending books for a particular user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/book_recommend_lightgcn_model_epochs30.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzuMPxFVZlQn"
   },
   "outputs": [],
   "source": [
    "bookid_title = pd.Series(items_df['title'].values, index=items_df.ISBN).to_dict()\n",
    "bookid_author = pd.Series(items_df['author'].values, index=items_df.ISBN).to_dict()\n",
    "user_pos_items = get_user_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, num_recs):\n",
    "    user = user_mapping.get(user_id)\n",
    "    print(\"user_idx is \", user)\n",
    "    if user is None:\n",
    "        print(f\"User ID {user_id} not found.\")\n",
    "        return [], []\n",
    "\n",
    "    emb_user = model.emb_users.weight[user]\n",
    "    ratings = model.emb_items.weight @ emb_user\n",
    "\n",
    "    values, indices = torch.topk(ratings, k=100)\n",
    "\n",
    "    ids = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n",
    "    titles = [bookid_title[id] for id in item_isbns]\n",
    "    authors = [bookid_author[id] for id in item_isbns]\n",
    "\n",
    "    print(f'Favorite books from user n{user_id}:')\n",
    "    for i in range(len(item_isbns)):\n",
    "        print(f'- {titles[i]}, by {authors[i]}')\n",
    "\n",
    "    ids = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n",
    "    titles = [bookid_title[id] for id in item_isbns]\n",
    "    authors = [bookid_author[id] for id in item_isbns]\n",
    "\n",
    "    print(f'\\nRecommended books for user n{user_id}')\n",
    "    for i in range(num_recs):\n",
    "        print(f'- {titles[i]}, by {authors[i]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(2084, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWR-LQUDaqgL"
   },
   "outputs": [],
   "source": [
    "recommend(3305, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(277427, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSFgwnaecWBw"
   },
   "outputs": [],
   "source": [
    "recommend(277427, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(2084, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend(1519, 5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recomd",
   "language": "python",
   "name": "recomd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7fa0016a911d70e86532c5706c9b4690ef8aee26a1d06018a1e37e463667ff8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
