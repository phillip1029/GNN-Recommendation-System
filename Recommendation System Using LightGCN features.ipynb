{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rWkNAZvtNQ6R"
   },
   "source": [
    "# Recommending Books using LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxoenua1-u5r",
    "outputId": "2718b918-3398-4e59-d95f-f028db2a5cb1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, Tensor\n",
    "import torch.sparse as sparse\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn import LGConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.version.cuda)         # Should print the CUDA version PyTorch is built with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aimer\\AppData\\Local\\Temp\\ipykernel_8960\\2270659622.py:15: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  items_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv('data/BX-Users.csv', sep=';', encoding='latin-1')\n",
    "# rename 'Location' and 'Age' to lowercase\n",
    "users_df.rename(columns={'Location': 'location', 'Age': 'age'}, inplace=True)\n",
    "# Example age bins\n",
    "bins = [0, 18, 35, 55, 75, float('inf')]\n",
    "labels = ['0-18', '19-35', '36-55', '56-75', '76+']\n",
    "\n",
    "users_df['age'].fillna(users_df['age'].median(), inplace=True)\n",
    "\n",
    "users_df['age_group'] = pd.cut(users_df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# rename 'User-ID' to 'user_id' \n",
    "users_df.rename(columns={'User-ID': 'user_id'}, inplace=True)\n",
    "\n",
    "items_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "# rename 'Book-Title' to 'title', 'Book-Author' to 'author'\n",
    "items_df.rename(columns={'Book-Title': 'title', 'Book-Author': 'author', 'Publisher':'publisher'}, inplace=True)\n",
    "# rename 'ISBN' to 'item_id'\n",
    "items_df.rename(columns={'ISBN': 'item_id'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author Year-Of-Publication                   publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                            location   age age_group\n",
       "0        1                  nyc, new york, usa  32.0     19-35\n",
       "1        2           stockton, california, usa  18.0     19-35\n",
       "2        3     moscow, yukon territory, russia  32.0     19-35\n",
       "3        4           porto, v.n.gaia, portugal  17.0      0-18\n",
       "4        5  farnborough, hants, united kingdom  32.0     19-35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author Year-Of-Publication                   publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df['author'] = items_df['author'].fillna('NA')\n",
    "items_df['publisher'] = items_df['publisher'].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                0\n",
       "title                  0\n",
       "author                 0\n",
       "Year-Of-Publication    0\n",
       "publisher              0\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with missing values\n",
    "# items_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     item_id  rating\n",
       "0   276725  034545104X       0\n",
       "1   276726  0155061224       5\n",
       "2   276727  0446520802       0\n",
       "3   276729  052165615X       3\n",
       "4   276729  0521795028       6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding='latin-1')  \n",
    "# rename 'User-ID' to 'user_id', 'Book-Rating' to 'rating', 'ISBN' to 'item_id'\n",
    "ratings_df.rename(columns={'User-ID': 'user_id', 'Book-Rating': 'rating', 'ISBN': 'item_id'}, inplace=True)\n",
    "ratings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149780, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full rating dataframe size:  (1031136, 3)\n",
      "subset rating dataframe size:  (223807, 3)\n",
      "(47074, 4)\n",
      "(98417, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessing\n",
    "ratings_df = ratings_df.loc[ratings_df['item_id'].isin(items_df['item_id'].unique()) & ratings_df['user_id'].isin(users_df['user_id'].unique())]\n",
    "\n",
    "print(\"full rating dataframe size: \", str(ratings_df.shape))\n",
    "# # Keep the 100k highest ratings\n",
    "ratings_df = ratings_df[ratings_df['rating'] >= 8] # .iloc[:100000]\n",
    "print(\"subset rating dataframe size: \", str(ratings_df.shape))\n",
    "\n",
    "# subsert users_df where user_id is in ratings_df\n",
    "users_df = users_df[users_df['user_id'].isin(ratings_df['user_id'].unique())].copy()\n",
    "# subsert items_df where item_id is in ratings_df\n",
    "items_df = items_df[items_df['item_id'].isin(ratings_df['item_id'].unique())].copy()\n",
    "\n",
    "print(users_df.shape)\n",
    "print(items_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "user_mapping = {userid: i for i, userid in enumerate(users_df['user_id'].unique())}\n",
    "item_mapping = {isbn: i for i, isbn in enumerate(items_df['item_id'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mapping[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save user_mapping\n",
    "with open('models/user_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(user_mapping, f)\n",
    "\n",
    "# Save item_mapping\n",
    "with open('models/item_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(item_mapping, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 47074 entries, 11 to 278853\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   user_id    47074 non-null  int64   \n",
      " 1   location   47074 non-null  object  \n",
      " 2   age        47074 non-null  float64 \n",
      " 3   age_group  47074 non-null  category\n",
      " 4   user_idx   47074 non-null  int64   \n",
      "dtypes: category(1), float64(1), int64(2), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Count users and items\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "num_total = num_users + num_items\n",
    "\n",
    "# Map user and item indices\n",
    "users_df['user_idx'] = users_df['user_id'].map(user_mapping)\n",
    "items_df['item_idx'] = items_df['item_id'].map(item_mapping)\n",
    "ratings_df['user_idx'] = ratings_df['user_id'].map(user_mapping)\n",
    "ratings_df['item_idx'] = ratings_df['item_id'].map(item_mapping)\n",
    "\n",
    "# Merge the user and item features with the ratings\n",
    "# merged_df = ratings_df.merge(users_df, on='user_id').merge(items_df, on='item_id')\n",
    "\n",
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.item_idx.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'title', 'author', 'Year-Of-Publication', 'publisher',\n",
       "       'Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'item_idx', 'subject_idx',\n",
       "       'author_idx'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>What If?: The World's Foremost Military Histor...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "5  0399135782                             The Kitchen God's Wife   \n",
       "6  0425176428  What If?: The World's Foremost Military Histor...   \n",
       "\n",
       "                 author Year-Of-Publication                 publisher  \\\n",
       "1  Richard Bruce Wright                2001     HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991           HarperPerennial   \n",
       "3      Gina Bari Kolata                1999      Farrar Straus Giroux   \n",
       "5               Amy Tan                1991          Putnam Pub Group   \n",
       "6         Robert Cowley                2000  Berkley Publishing Group   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "5  http://images.amazon.com/images/P/0399135782.0...   \n",
       "6  http://images.amazon.com/images/P/0425176428.0...   \n",
       "\n",
       "                                         Image-URL-L  item_idx  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...         0  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...         1  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...         2  \n",
       "5  http://images.amazon.com/images/P/0399135782.0...         3  \n",
       "6  http://images.amazon.com/images/P/0425176428.0...         4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset: transforming the user features and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                0\n",
       "title                  0\n",
       "author                 0\n",
       "Year-Of-Publication    0\n",
       "publisher              0\n",
       "Image-URL-S            0\n",
       "Image-URL-M            0\n",
       "Image-URL-L            0\n",
       "item_idx               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # fill missing values of locations, age_group, subject, author with 'unknown'\n",
    "# def fillna_category(df, column):\n",
    "#     df[column] = df[column].astype('category')\n",
    "#     df[column].cat.add_categories('unknown')\n",
    "#     df[column].fillna('unknown', inplace=True)\n",
    "\n",
    "# check if there are any missing values\n",
    "items_df.isna().sum()\n",
    "\n",
    "# delete rows with missing values in 'title' and 'author'\n",
    "# items_df.dropna(subset=['title', 'author'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to map categories to indices\n",
    "def map_categories(df, column):\n",
    "    unique_values = df[column].unique()\n",
    "    value_to_idx = {value: idx for idx, value in enumerate(unique_values)}\n",
    "    return df[column].map(value_to_idx), len(unique_values)\n",
    "\n",
    "# Map each categorical feature\n",
    "users_df['location_idx'], num_locations = map_categories(users_df, 'location')\n",
    "users_df['age_group_idx'], num_age_groups = map_categories(users_df, 'age_group')\n",
    "items_df['subject_idx'], num_subjects = map_categories(items_df, 'publisher')\n",
    "items_df['author_idx'], num_authors = map_categories(items_df, 'author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Input data for the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indices to tensors\n",
    "user_location_indices = torch.tensor(users_df['location_idx'].values, dtype=torch.long)\n",
    "user_age_group_indices = torch.tensor(users_df['age_group_idx'].values, dtype=torch.long)\n",
    "item_subject_indices = torch.tensor(items_df['subject_idx'].values, dtype=torch.long)\n",
    "item_author_indices = torch.tensor(items_df['author_idx'].values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HeteroData\n",
    "data = HeteroData()\n",
    "\n",
    "# Assigning integer-encoded features\n",
    "data['user'].x = torch.cat([user_location_indices.unsqueeze(1), user_age_group_indices.unsqueeze(1)], dim=1)\n",
    "data['item'].x = torch.cat([item_subject_indices.unsqueeze(1), item_author_indices.unsqueeze(1)], dim=1)\n",
    "\n",
    "# Creating edge index from ratings dataframe\n",
    "edge_index = torch.tensor(ratings_df[['user_idx', 'item_idx']].values.T, dtype=torch.long)\n",
    "edge_features = torch.tensor(ratings_df['rating'].values, dtype=torch.float)\n",
    "# Create edge labels based on the rating\n",
    "edge_labels = (edge_features >= 8).long()  # This will create a tensor of 0s and 1s\n",
    "\n",
    "# Assign edge features (ratings), edge type = 'Rating Edge'\n",
    "data['user', 'Rating Edge', 'item'].edge_index = edge_index\n",
    "data['user', 'Rating Edge', 'item'].edge_attr = edge_features\n",
    "# Assign edge labels to the HeteroData object\n",
    "data['user', 'Rating Edge', 'item'].edge_label = edge_labels\n",
    "# Assign edge label indices (in this case, they are the same as edge indices)\n",
    "data['user', 'Rating Edge', 'item'].edge_label_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[47074, 2] },\n",
       "  item={ x=[98417, 2] },\n",
       "  (user, Rating Edge, item)={\n",
       "    edge_index=[2, 223807],\n",
       "    edge_attr=[223807],\n",
       "    edge_label=[223807],\n",
       "    edge_label_index=[2, 223807],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in ratings_df.\n",
      "User and Item indices in ratings_df are correctly aligned.\n",
      "No duplicate user-item pairs in ratings_df.\n",
      "User and Item indices in ratings_df are continuous.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming ratings_df, users_df, and items_df are your DataFrames\n",
    "\n",
    "# 1. Check for Invalid or Missing Values in ratings_df\n",
    "if ratings_df.isnull().values.any():\n",
    "    print(\"There are missing values in ratings_df.\")\n",
    "else:\n",
    "    print(\"No missing values in ratings_df.\")\n",
    "\n",
    "# 2. Verify User and Item Index Alignment\n",
    "max_user_idx = ratings_df['user_idx'].max()\n",
    "max_item_idx = ratings_df['item_idx'].max()\n",
    "\n",
    "if max_user_idx >= len(users_df) or max_item_idx >= len(items_df):\n",
    "    print(\"User or Item indices in ratings_df exceed the number of rows in users_df or items_df.\")\n",
    "else:\n",
    "    print(\"User and Item indices in ratings_df are correctly aligned.\")\n",
    "\n",
    "# 3. Check for Duplicate Rows\n",
    "if ratings_df.duplicated(subset=['user_idx', 'item_idx']).any():\n",
    "    print(\"There are duplicate user-item pairs in ratings_df.\")\n",
    "else:\n",
    "    print(\"No duplicate user-item pairs in ratings_df.\")\n",
    "\n",
    "# 4. Inspect Index Continuity\n",
    "user_idx_continuous = set(ratings_df['user_idx']) == set(range(max_user_idx + 1))\n",
    "item_idx_continuous = set(ratings_df['item_idx']) == set(range(max_item_idx + 1))\n",
    "\n",
    "if not user_idx_continuous or not item_idx_continuous:\n",
    "    print(\"User or Item indices in ratings_df are not continuous.\")\n",
    "else:\n",
    "    print(\"User and Item indices in ratings_df are continuous.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every edge has a corresponding label.\n"
     ]
    }
   ],
   "source": [
    "# Assuming edge_labels is a tensor of edge labels\n",
    "\n",
    "# Number of edges in ratings_df\n",
    "num_edges_in_df = ratings_df.shape[0]\n",
    "\n",
    "# Number of labels in edge_labels\n",
    "num_labels = edge_labels.shape[0]\n",
    "\n",
    "# Check if every edge has a corresponding label\n",
    "if num_edges_in_df == num_labels:\n",
    "    print(\"Every edge has a corresponding label.\")\n",
    "else:\n",
    "    print(f\"Mismatch: {num_edges_in_df} edges in DataFrame, but {num_labels} labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User indices start from 0 and are continuous.\n",
      "Item indices start from 0 and are continuous.\n"
     ]
    }
   ],
   "source": [
    "# Check if indices start from 0 and are continuous\n",
    "\n",
    "# Check for user indices\n",
    "min_user_idx = ratings_df['user_idx'].min()\n",
    "max_user_idx = ratings_df['user_idx'].max()\n",
    "user_indices_continuous = set(ratings_df['user_idx']) == set(range(min_user_idx, max_user_idx + 1))\n",
    "\n",
    "# Check for item indices\n",
    "min_item_idx = ratings_df['item_idx'].min()\n",
    "max_item_idx = ratings_df['item_idx'].max()\n",
    "item_indices_continuous = set(ratings_df['item_idx']) == set(range(min_item_idx, max_item_idx + 1))\n",
    "\n",
    "# Print the results\n",
    "if min_user_idx != 0 or not user_indices_continuous:\n",
    "    print(\"User indices are either not starting from 0 or not continuous.\")\n",
    "else:\n",
    "    print(\"User indices start from 0 and are continuous.\")\n",
    "\n",
    "if min_item_idx != 0 or not item_indices_continuous:\n",
    "    print(\"Item indices are either not starting from 0 or not continuous.\")\n",
    "else:\n",
    "    print(\"Item indices start from 0 and are continuous.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(edge_index, edge_attr, proportions=(0.8, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Splits the edges of a graph into training, validation, and test sets.\n",
    "\n",
    "    This function randomly shuffles the edges of a graph and then splits them into\n",
    "    three subsets according to the specified proportions. It is primarily used in\n",
    "    graph learning tasks where you need separate edge sets for training, validation,\n",
    "    and testing the model.\n",
    "\n",
    "    Parameters:\n",
    "    edge_index (Tensor): A 2xN tensor where N is the number of edges, and each column\n",
    "                         represents an edge in the format [source, target].\n",
    "    edge_attr (Tensor): A tensor containing attributes for each edge in edge_index.\n",
    "                        The length of this tensor should match the number of edges in edge_index.\n",
    "    proportions (tuple, optional): A tuple representing the proportions for splitting the edges\n",
    "                                    into training, validation, and test sets. Defaults to (0.8, 0.1, 0.1).\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing three tuples, each for the training, validation, and test sets.\n",
    "           Each inner tuple contains a subset of edge_index and the corresponding edge_attr.\n",
    "           Format: ((train_edge_index, train_edge_attr),\n",
    "                    (val_edge_index, val_edge_attr),\n",
    "                    (test_edge_index, test_edge_attr))\n",
    "    \"\"\"\n",
    "    num_edges = edge_index.size(1)\n",
    "    all_indices = torch.randperm(num_edges)\n",
    "\n",
    "    train_size = int(proportions[0] * num_edges)\n",
    "    val_size = int(proportions[1] * num_edges)\n",
    "\n",
    "    train_indices = all_indices[:train_size]\n",
    "    val_indices = all_indices[train_size:train_size + val_size]\n",
    "    test_indices = all_indices[train_size + val_size:]\n",
    "\n",
    "    return (edge_index[:, train_indices], edge_attr[train_indices]), \\\n",
    "           (edge_index[:, val_indices], edge_attr[val_indices]), \\\n",
    "           (edge_index[:, test_indices], edge_attr[test_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_subset(source_data, edge_index, edge_attr, edge_label_index, edge_label):\n",
    "    \"\"\"\n",
    "    Creates a subset of graph data from a source heterogeneous graph.\n",
    "\n",
    "    This function constructs a new HeteroData object (a heterogeneous graph representation) \n",
    "    by selecting specific edges and their attributes from the source data. It's typically \n",
    "    used in graph neural network tasks to create subsets of data for training, validation, \n",
    "    or testing. The function assumes the graph has a bipartite structure with 'user' and \n",
    "    'item' node types and edges representing 'Rating Edge'.\n",
    "\n",
    "    Parameters:\n",
    "    source_data (HeteroData): The source heterogeneous graph data from which the subset is created.\n",
    "                              This should be an instance of HeteroData with 'user' and 'item' node types.\n",
    "    edge_index (Tensor): A 2xN tensor specifying the edges in the subset. Each column is an edge\n",
    "                         in the format [source, target], typically representing a 'user'-'item' interaction.\n",
    "    edge_attr (Tensor): A tensor containing attributes for each edge specified in edge_index.\n",
    "    edge_label_index (Tensor): A 2xM tensor specifying the edges for which labels are provided.\n",
    "                               This is typically a subset or the same as edge_index.\n",
    "    edge_label (Tensor): A tensor containing labels for each edge specified in edge_label_index.\n",
    "\n",
    "    Returns:\n",
    "    HeteroData: A new HeteroData object representing the subset of the original graph. This subset\n",
    "                includes node features for 'user' and 'item' types and the specified edges with their\n",
    "                attributes and labels.\n",
    "    \"\"\"\n",
    "    subset = HeteroData()\n",
    "    subset['user'].x = source_data['user'].x\n",
    "    subset['item'].x = source_data['item'].x\n",
    "    subset['user', 'Rating Edge', 'item'].edge_index = edge_index\n",
    "    subset['user', 'Rating Edge', 'item'].edge_attr = edge_attr\n",
    "    subset['user', 'Rating Edge', 'item'].edge_label_index = edge_label_index\n",
    "    subset['user', 'Rating Edge', 'item'].edge_label = edge_label\n",
    "    return subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edges(edge_index, edge_attr, edge_label_index, edge_label, proportions=(0.8, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Splits the edges of a graph into training, validation, and test sets.\n",
    "\n",
    "    This function shuffles and divides the edges of a graph into three subsets based on\n",
    "    the specified proportions. It is useful for preparing graph data for machine learning tasks,\n",
    "    ensuring distinct edge sets for training, validation, and testing phases.\n",
    "\n",
    "    Parameters:\n",
    "    edge_index (Tensor): A 2xN tensor with each column representing an edge as [source, target].\n",
    "    edge_attr (Tensor): Attributes associated with each edge in edge_index.\n",
    "    edge_label_index (Tensor): A 2xN tensor specifying the edges for which labels are provided.\n",
    "    edge_label (Tensor): Labels for each edge specified in edge_label_index.\n",
    "    proportions (tuple of float, optional): The proportions to split the edges into training,\n",
    "                                            validation, and test sets. Defaults to (0.8, 0.1, 0.1).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Three tuples corresponding to the training, validation, and test sets. Each tuple contains\n",
    "           the edge_index, edge_attr, edge_label_index, and edge_label for that subset.\n",
    "    \"\"\"\n",
    "    num_edges = edge_index.size(1)\n",
    "    all_indices = torch.randperm(num_edges)\n",
    "\n",
    "    train_size = int(proportions[0] * num_edges)\n",
    "    val_size = int(proportions[1] * num_edges)\n",
    "\n",
    "    train_indices = all_indices[:train_size]\n",
    "    val_indices = all_indices[train_size:train_size + val_size]\n",
    "    test_indices = all_indices[train_size + val_size:]\n",
    "\n",
    "    return ((edge_index[:, train_indices], edge_attr[train_indices],\n",
    "             edge_label_index[:, train_indices], edge_label[train_indices]),\n",
    "            (edge_index[:, val_indices], edge_attr[val_indices],\n",
    "             edge_label_index[:, val_indices], edge_label[val_indices]),\n",
    "            (edge_index[:, test_indices], edge_attr[test_indices],\n",
    "             edge_label_index[:, test_indices], edge_label[test_indices]))\n",
    "\n",
    "# Apply the split\n",
    "train_split, val_split, test_split = split_edges(\n",
    "    data['user', 'Rating Edge', 'item'].edge_index, \n",
    "    data['user', 'Rating Edge', 'item'].edge_attr,\n",
    "    data['user', 'Rating Edge', 'item'].edge_label_index,\n",
    "    data['user', 'Rating Edge', 'item'].edge_label\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_data = create_data_subset(data, *train_split)\n",
    "val_data = create_data_subset(data, *val_split)\n",
    "test_data = create_data_subset(data, *test_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[47074, 2] },\n",
       "  item={ x=[98417, 2] },\n",
       "  (user, Rating Edge, item)={\n",
       "    edge_index=[2, 179045],\n",
       "    edge_attr=[179045],\n",
       "    edge_label_index=[2, 179045],\n",
       "    edge_label=[179045],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[47074, 2] },\n",
       "  item={ x=[98417, 2] },\n",
       "  (user, Rating Edge, item)={\n",
       "    edge_index=[2, 22380],\n",
       "    edge_attr=[22380],\n",
       "    edge_label_index=[2, 22380],\n",
       "    edge_label=[22380],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The critical purpose of graph dataloader is to create mini-batches so that the model training won't take too much resources to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "# Assuming `data` is your HeteroData object\n",
    "# Assuming edge_label_index and edge_labels are already defined in data\n",
    "\n",
    "# Configure the LinkLoader\n",
    "train_edge_label_index = train_data['user', 'Rating Edge', 'item'].edge_label_index\n",
    "train_edge_label = train_data['user', 'Rating Edge', 'item'].edge_label\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=1.0,  # Ratio of negative samples to positive samples    \n",
    "    edge_label_index=(('user', 'Rating Edge', 'item'), train_edge_label_index),\n",
    "    edge_label=train_edge_label,\n",
    "    batch_size=128,  # Define your batch size\n",
    "    shuffle=True  # Shuffle the data for training\n",
    ")\n",
    "\n",
    "# Configure the LinkLoader\n",
    "val_edge_label_index = val_data['user', 'Rating Edge', 'item'].edge_label_index\n",
    "val_edge_label = val_data['user', 'Rating Edge', 'item'].edge_label\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=1.0,  # Ratio of negative samples to positive samples    \n",
    "    edge_label_index=(('user', 'Rating Edge', 'item'), val_edge_label_index),\n",
    "    edge_label=val_edge_label,\n",
    "    batch_size=128,  # Define your batch size\n",
    "    shuffle=True  # Shuffle the data for training\n",
    ")\n",
    "\n",
    "# Configure the LinkLoader\n",
    "test_edge_label_index = test_data['user', 'Rating Edge', 'item'].edge_label_index\n",
    "test_edge_label = test_data['user', 'Rating Edge', 'item'].edge_label\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    neg_sampling_ratio=1.0,  # Ratio of negative samples to positive samples    \n",
    "    edge_label_index=(('user', 'Rating Edge', 'item'), test_edge_label_index),\n",
    "    edge_label=test_edge_label,\n",
    "    batch_size=128,  # Define your batch size\n",
    "    shuffle=True  # Shuffle the data for training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ x=[47074, 2] },\n",
       "  item={ x=[98417, 2] },\n",
       "  (user, Rating Edge, item)={\n",
       "    edge_index=[2, 179045],\n",
       "    edge_attr=[179045],\n",
       "    edge_label_index=[2, 179045],\n",
       "    edge_label=[179045],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JOB5kDmtUrUY"
   },
   "source": [
    "## Implementing the LightGCN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* specify the model architectures which include node features and edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.sparse import mm as sparse_mm\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, num_layers,\n",
    "                 num_locations, num_age_groups, num_subjects, num_authors):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize user and item embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Initialize additional feature embeddings\n",
    "        self.location_embedding = nn.Embedding(num_locations, embedding_dim)\n",
    "        self.age_group_embedding = nn.Embedding(num_age_groups, embedding_dim)\n",
    "        self.subject_embedding = nn.Embedding(num_subjects, embedding_dim)\n",
    "        self.author_embedding = nn.Embedding(num_authors, embedding_dim)\n",
    "\n",
    "        # Initialization\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.location_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.age_group_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.subject_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.author_embedding.weight, std=0.1)\n",
    "\n",
    "    def forward(self, user_indices, item_indices, location_indices, age_group_indices, subject_indices, author_indices, adj_matrix):\n",
    "        # Initial user and item embeddings\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "\n",
    "        # Embeddings for additional features\n",
    "        location_emb = self.location_embedding(location_indices)\n",
    "        age_group_emb = self.age_group_embedding(age_group_indices)\n",
    "        subject_emb = self.subject_embedding(subject_indices)\n",
    "        author_emb = self.author_embedding(author_indices)\n",
    "\n",
    "        # Combine base embeddings with feature embeddings\n",
    "        user_emb = user_emb + location_emb + age_group_emb\n",
    "        item_emb = item_emb + subject_emb + author_emb\n",
    "\n",
    "        # Debug: Print dimensions for troubleshooting\n",
    "        print(\"Adjacency Matrix Shape:\", adj_matrix.shape)\n",
    "        print(\"User Embeddings Shape:\", user_emb.shape)\n",
    "        print(\"Item Embeddings Shape:\", item_emb.shape)\n",
    "\n",
    "        all_embeddings = torch.cat([user_emb, item_emb], dim=0)\n",
    "\n",
    "        print(\"All Embeddings Shape:\", all_embeddings.shape)\n",
    "\n",
    "        # List to hold all embeddings for each layer\n",
    "        all_user_embs = [user_emb]\n",
    "        all_item_embs = [item_emb]\n",
    "\n",
    "        # Perform graph convolutions\n",
    "        for _ in range(self.num_layers):\n",
    "            # Ensure dimensions are compatible for matrix multiplication\n",
    "            if adj_matrix.shape[0] != all_embeddings.shape[0]:\n",
    "                raise ValueError(\"Dimension mismatch: adj_matrix and all_embeddings must have the same number of rows\")\n",
    "\n",
    "            all_embeddings = sparse_mm(adj_matrix, all_embeddings)\n",
    "\n",
    "            user_emb = all_embeddings[:self.num_users]\n",
    "            item_emb = all_embeddings[self.num_users:]\n",
    "\n",
    "            all_user_embs.append(user_emb)\n",
    "            all_item_embs.append(item_emb)\n",
    "\n",
    "        # Compute final embeddings as the mean of all layers' embeddings\n",
    "        final_user_emb = torch.mean(torch.stack(all_user_embs), dim=0)\n",
    "        final_item_emb = torch.mean(torch.stack(all_item_embs), dim=0)\n",
    "\n",
    "        # Predict ratings by computing the dot product of user and item embeddings\n",
    "        scores = torch.sum(final_user_emb * final_item_emb, dim=1)\n",
    "\n",
    "        self.cached_embeddings = all_embeddings  # Cache the embeddings\n",
    "\n",
    "        return scores\n",
    "    \n",
    "    def get_user_embeddings(self, user_indices):\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        # You can add additional features if necessary\n",
    "        return user_emb\n",
    "\n",
    "    def get_item_embeddings(self, item_indices):\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        # You can add additional features if necessary\n",
    "        return item_emb\n",
    "\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "# model = LightGCN(num_users=1000, num_items=500, embedding_dim=64, num_layers=3,\n",
    "#                  num_locations=10, num_age_groups=5, num_subjects=20, num_authors=50)\n",
    "# ... (setup data and training loop) ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb, pos_items_emb, neg_items_emb):\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) loss using log sigmoid.\n",
    "    \n",
    "    Args:\n",
    "        users_emb (Tensor): Embeddings of users.\n",
    "        pos_items_emb (Tensor): Embeddings of positive items.\n",
    "        neg_items_emb (Tensor): Embeddings of negative items.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: BPR loss.\n",
    "    \"\"\"\n",
    "    pos_scores = (users_emb * pos_items_emb).sum(dim=1)\n",
    "    neg_scores = (users_emb * neg_items_emb).sum(dim=1)\n",
    "    scores = pos_scores - neg_scores\n",
    "\n",
    "    # Debugging: Check the range of scores\n",
    "    print(\"Max score:\", scores.max().item(), \"Min score:\", scores.min().item())\n",
    "\n",
    "    loss = -torch.mean(torch.nn.functional.logsigmoid(scores))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When computing the logarithm of the sigmoid function, there's a risk of numerical instability, especially when the argument of the sigmoid function (pos_scores - neg_scores) takes large positive or negative values. In these cases, the sigmoid function can return values very close to 0 or 1, leading to issues when taking the logarithm (since log(0) is undefined and can lead to nan values).\n",
    "* \n",
    "To enhance the stability, you can use the torch.nn.functional.logsigmoid function, which is a numerically stable version of the logarithm of the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGCN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of locations: 14239\n",
      "Number of age groups: 5\n",
      "Number of subjects: 8751\n",
      "Number of authors: 42696\n",
      "Number of users: 47074\n",
      "Number of items: 98417\n"
     ]
    }
   ],
   "source": [
    "# Number of unique locations\n",
    "num_locations = data['user'].x[:, 0].unique().size(0)\n",
    "# Number of unique age groups\n",
    "num_age_groups = data['user'].x[:, 1].unique().size(0)\n",
    "\n",
    "# Number of unique subjects\n",
    "num_subjects = data['item'].x[:, 0].unique().size(0)\n",
    "# Number of unique authors\n",
    "num_authors = data['item'].x[:, 1].unique().size(0)\n",
    "# Number of unique users\n",
    "num_users = data['user', 'Rating Edge', 'item'].edge_index[0].unique().size(0)\n",
    "# Number of unique items\n",
    "num_items = data['user', 'Rating Edge', 'item'].edge_index[1].unique().size(0)\n",
    "\n",
    "print(\"Number of locations:\", num_locations)\n",
    "print(\"Number of age groups:\", num_age_groups)\n",
    "print(\"Number of subjects:\", num_subjects)\n",
    "print(\"Number of authors:\", num_authors)\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the LightGCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LightGCN model\n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_items, \n",
    "                 embedding_dim=64, \n",
    "                 num_layers=3,\n",
    "                 num_locations=num_locations, \n",
    "                 num_age_groups=num_age_groups, \n",
    "                 num_subjects=num_subjects, \n",
    "                 num_authors=num_authors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Define your loss function (assuming BPR loss)\n",
    "def bpr_loss(users_emb, pos_items_emb, neg_items_emb):\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) loss using log sigmoid.\n",
    "    \n",
    "    Args:\n",
    "        users_emb (Tensor): Embeddings of users.\n",
    "        pos_items_emb (Tensor): Embeddings of positive items.\n",
    "        neg_items_emb (Tensor): Embeddings of negative items.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: BPR loss.\n",
    "    \"\"\"\n",
    "    pos_scores = (users_emb * pos_items_emb).sum(dim=1)\n",
    "    neg_scores = (users_emb * neg_items_emb).sum(dim=1)\n",
    "    scores = pos_scores - neg_scores\n",
    "\n",
    "    # Debugging: Check the range of scores\n",
    "    # print(\"Max score:\", scores.max().item(), \"Min score:\", scores.min().item())\n",
    "\n",
    "    loss = -torch.mean(torch.nn.functional.logsigmoid(scores))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training Loss: 0.6369, Validation Loss: 0.5548, Test Loss: 0.5572\n",
      "Epoch 2/10 - Training Loss: 0.5415, Validation Loss: 0.5290, Test Loss: 0.5263\n",
      "Epoch 3/10 - Training Loss: 0.5202, Validation Loss: 0.5191, Test Loss: 0.5162\n",
      "Epoch 4/10 - Training Loss: 0.5152, Validation Loss: 0.5129, Test Loss: 0.5100\n",
      "Epoch 5/10 - Training Loss: 0.5122, Validation Loss: 0.5097, Test Loss: 0.5118\n",
      "Epoch 6/10 - Training Loss: 0.5115, Validation Loss: 0.5128, Test Loss: 0.5126\n",
      "Epoch 7/10 - Training Loss: 0.5121, Validation Loss: 0.5096, Test Loss: 0.5082\n",
      "Epoch 8/10 - Training Loss: 0.5099, Validation Loss: 0.5121, Test Loss: 0.5102\n",
      "Epoch 9/10 - Training Loss: 0.5096, Validation Loss: 0.5120, Test Loss: 0.5135\n",
      "Epoch 10/10 - Training Loss: 0.5095, Validation Loss: 0.5039, Test Loss: 0.5095\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming the LightGCN model is defined as LightGCN\n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_items, \n",
    "                 embedding_dim=64,  # Example embedding dimension\n",
    "                 num_layers=3,      # Example number of layers\n",
    "                 num_locations=num_locations, \n",
    "                 num_age_groups=num_age_groups, \n",
    "                 num_subjects=num_subjects, \n",
    "                 num_authors=num_authors)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        edge_label_index = batch['user', 'Rating Edge', 'item'].edge_label_index\n",
    "        edge_labels = batch['user', 'Rating Edge', 'item'].edge_label\n",
    "\n",
    "        user_indices = edge_label_index[0]\n",
    "        item_indices = edge_label_index[1]\n",
    "\n",
    "        pos_item_indices = item_indices[edge_labels == 1]\n",
    "        neg_item_indices = item_indices[edge_labels == 0]\n",
    "\n",
    "        # Limit the number of samples to the smallest size\n",
    "        min_size = min(user_indices.size(0), pos_item_indices.size(0), neg_item_indices.size(0))\n",
    "        user_indices = user_indices[:min_size]\n",
    "        pos_item_indices = pos_item_indices[:min_size]\n",
    "        neg_item_indices = neg_item_indices[:min_size]\n",
    "\n",
    "        # Get embeddings\n",
    "        users_emb = model.get_user_embeddings(user_indices)\n",
    "        pos_items_emb = model.get_item_embeddings(pos_item_indices)\n",
    "        neg_items_emb = model.get_item_embeddings(neg_item_indices)\n",
    "\n",
    "        # Compute BPR loss\n",
    "        loss = bpr_loss(users_emb, pos_items_emb, neg_items_emb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            edge_label_index = batch['user', 'Rating Edge', 'item'].edge_label_index\n",
    "            edge_labels = batch['user', 'Rating Edge', 'item'].edge_label\n",
    "\n",
    "            user_indices = edge_label_index[0]\n",
    "            item_indices = edge_label_index[1]\n",
    "\n",
    "            pos_item_indices = item_indices[edge_labels == 1]\n",
    "            neg_item_indices = item_indices[edge_labels == 0]\n",
    "\n",
    "            # Limit the number of samples to the smallest size\n",
    "            min_size = min(user_indices.size(0), pos_item_indices.size(0), neg_item_indices.size(0))\n",
    "            user_indices = user_indices[:min_size]\n",
    "            pos_item_indices = pos_item_indices[:min_size]\n",
    "            neg_item_indices = neg_item_indices[:min_size]\n",
    "\n",
    "            users_emb = model.get_user_embeddings(user_indices)\n",
    "            pos_items_emb = model.get_item_embeddings(pos_item_indices)\n",
    "            neg_items_emb = model.get_item_embeddings(neg_item_indices)\n",
    "\n",
    "            loss = bpr_loss(users_emb, pos_items_emb, neg_items_emb)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            edge_label_index = batch['user', 'Rating Edge', 'item'].edge_label_index\n",
    "            edge_labels = batch['user', 'Rating Edge', 'item'].edge_label\n",
    "\n",
    "            user_indices = edge_label_index[0]\n",
    "            item_indices = edge_label_index[1]\n",
    "\n",
    "            pos_item_indices = item_indices[edge_labels == 1]\n",
    "            neg_item_indices = item_indices[edge_labels == 0]\n",
    "\n",
    "            # Limit the number of samples to the smallest size\n",
    "            min_size = min(user_indices.size(0), pos_item_indices.size(0), neg_item_indices.size(0))\n",
    "            user_indices = user_indices[:min_size]\n",
    "            pos_item_indices = pos_item_indices[:min_size]\n",
    "            neg_item_indices = neg_item_indices[:min_size]\n",
    "\n",
    "            users_emb = model.get_user_embeddings(user_indices)\n",
    "            pos_items_emb = model.get_item_embeddings(pos_item_indices)\n",
    "            neg_items_emb = model.get_item_embeddings(neg_item_indices)\n",
    "\n",
    "            loss = bpr_loss(users_emb, pos_items_emb, neg_items_emb)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "\n",
    "# Assuming model, train_loader, val_loader, and optimizer are already defined\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    val_loss = validate(model, val_loader)\n",
    "    test_loss = test(model, test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'models/lightgcn_model_with_features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of locations: 14239\n",
      "Number of age groups: 5\n",
      "Number of subjects: 8751\n",
      "Number of authors: 42696\n",
      "Number of users: 47074\n",
      "Number of items: 98417\n"
     ]
    }
   ],
   "source": [
    "# Number of unique locations\n",
    "num_locations = data['user'].x[:, 0].unique().size(0)\n",
    "# Number of unique age groups\n",
    "num_age_groups = data['user'].x[:, 1].unique().size(0)\n",
    "\n",
    "# Number of unique subjects\n",
    "num_subjects = data['item'].x[:, 0].unique().size(0)\n",
    "# Number of unique authors\n",
    "num_authors = data['item'].x[:, 1].unique().size(0)\n",
    "# Number of unique users\n",
    "num_users = data['user', 'Rating Edge', 'item'].edge_index[0].unique().size(0)\n",
    "# Number of unique items\n",
    "num_items = data['user', 'Rating Edge', 'item'].edge_index[1].unique().size(0)\n",
    "\n",
    "print(\"Number of locations:\", num_locations)\n",
    "print(\"Number of age groups:\", num_age_groups)\n",
    "print(\"Number of subjects:\", num_subjects)\n",
    "print(\"Number of authors:\", num_authors)\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGCN(\n",
       "  (user_embedding): Embedding(47074, 64)\n",
       "  (item_embedding): Embedding(98417, 64)\n",
       "  (location_embedding): Embedding(14239, 64)\n",
       "  (age_group_embedding): Embedding(5, 64)\n",
       "  (subject_embedding): Embedding(8751, 64)\n",
       "  (author_embedding): Embedding(42696, 64)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the LightGCN class and other parameters (like num_users, num_items, etc.) are defined\n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_items, \n",
    "                 embedding_dim=64, \n",
    "                 num_layers=3, \n",
    "                 num_locations=num_locations, \n",
    "                 num_age_groups=num_age_groups, \n",
    "                 num_subjects=num_subjects, \n",
    "                 num_authors=num_authors)\n",
    "\n",
    "model.load_state_dict(torch.load('models/lightgcn_model_with_features.pt'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_all_items_batched(model, num_users, num_items, batch_size=1000):\n",
    "    all_scores = torch.zeros(num_users, num_items)\n",
    "\n",
    "    # Iterate over users in batches\n",
    "    for user_batch_start in range(0, num_users, batch_size):\n",
    "        user_batch_end = min(user_batch_start + batch_size, num_users)\n",
    "        user_indices = torch.arange(user_batch_start, user_batch_end)\n",
    "        user_embeddings = model.get_user_embeddings(user_indices)\n",
    "\n",
    "        # Iterate over items in batches\n",
    "        for item_batch_start in range(0, num_items, batch_size):\n",
    "            item_batch_end = min(item_batch_start + batch_size, num_items)\n",
    "            item_indices = torch.arange(item_batch_start, item_batch_end)\n",
    "            item_embeddings = model.get_item_embeddings(item_indices)\n",
    "\n",
    "            # Compute scores for the current batch\n",
    "            batch_scores = torch.mm(user_embeddings, item_embeddings.t())\n",
    "            all_scores[user_batch_start:user_batch_end, item_batch_start:item_batch_end] = batch_scores\n",
    "\n",
    "    return all_scores\n",
    "\n",
    "\n",
    "def exclude_interacted_items(scores, interaction_history):\n",
    "    for user_id in range(scores.size(0)):\n",
    "        interacted_items = interaction_history.get(user_id, [])\n",
    "        scores[user_id, interacted_items] = -float('inf')\n",
    "    return scores\n",
    "\n",
    "def get_top_k_recommendations(scores, k=5):\n",
    "    top_k_items = torch.topk(scores, k, dim=1).indices\n",
    "    return top_k_items\n",
    "\n",
    "def get_interaction_history(data):\n",
    "    interaction_history = {}\n",
    "\n",
    "    edge_index = data['user', 'Rating Edge', 'item'].edge_index\n",
    "\n",
    "    # Iterate over all interactions (both positive and negative)\n",
    "    for index in range(edge_index.size(1)):  # Iterate over the number of edges\n",
    "        user_id = edge_index[0, index].item()\n",
    "        item_id = edge_index[1, index].item()\n",
    "\n",
    "        if user_id not in interaction_history:\n",
    "            interaction_history[user_id] = []\n",
    "        interaction_history[user_id].append(item_id)\n",
    "\n",
    "    return interaction_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0: tensor([0, 2, 3, 1, 8])\n",
      "User 1: tensor([0, 3, 2, 1, 5])\n",
      "User 2: tensor([0, 3, 2, 6, 1])\n",
      "User 3: tensor([0, 3, 2, 1, 5])\n",
      "User 4: tensor([0, 3, 2, 1, 5])\n",
      "User 5: tensor([0, 3, 2, 1, 5])\n",
      "User 6: tensor([0, 3, 2, 5, 1])\n",
      "User 7: tensor([0, 3, 2, 1, 5])\n",
      "User 8: tensor([0, 2, 3, 1, 5])\n",
      "User 9: tensor([0, 3, 2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interaction_history = get_interaction_history(data)\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load('models/lightgcn_model_with_features.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Score all items for each user\n",
    "scores = score_all_items_batched(model, num_users, num_items,  batch_size=500)\n",
    "\n",
    "# Exclude already interacted items\n",
    "scores = exclude_interacted_items(scores, interaction_history)\n",
    "\n",
    "# Get top-5 recommendations\n",
    "top_5_recommendations = get_top_k_recommendations(scores, k=5)\n",
    "\n",
    "# Display the recommendations\n",
    "for user_id in range(10):  # Modify as needed for your specific use case\n",
    "    print(f\"User {user_id}: {top_5_recommendations[user_id]}\")\n",
    "\n",
    "# save top_5_recommendations to a pands dataframe and a csv file\n",
    "top_5_recommendations_df = pd.DataFrame(top_5_recommendations)\n",
    "top_5_recommendations_df.to_csv('data/top_5_recommendations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>item3</th>\n",
       "      <th>item4</th>\n",
       "      <th>item5</th>\n",
       "      <th>user_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item1  item2  item3  item4  item5  user_idx\n",
       "0      0      2      3      1      8         0\n",
       "1      0      3      2      1      5         1\n",
       "2      0      3      2      6      1         2\n",
       "3      0      3      2      1      5         3\n",
       "4      0      3      2      1      5         4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_recommendations_df.columns = ['item1', 'item2', 'item3', 'item4', 'item5']\n",
    "# turn index into user_idx column in top_5_recommendations_df\n",
    "top_5_recommendations_df['user_idx'] = top_5_recommendations_df.index\n",
    "top_5_recommendations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>item3</th>\n",
       "      <th>item4</th>\n",
       "      <th>item5</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>fort bragg, california, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>albuquerque, new mexico, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>bellevue, washington, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>cary, north carolina, usa</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19-35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item1  item2  item3  item4  item5  user_idx  user_id  \\\n",
       "0      0      2      3      1      8         0       12   \n",
       "1      0      3      2      1      5         1       16   \n",
       "2      0      3      2      6      1         2       26   \n",
       "3      0      3      2      1      5         3       32   \n",
       "4      0      3      2      1      5         4       39   \n",
       "\n",
       "                       location   age age_group  \n",
       "0   fort bragg, california, usa  32.0     19-35  \n",
       "1  albuquerque, new mexico, usa  32.0     19-35  \n",
       "2     bellevue, washington, usa  32.0     19-35  \n",
       "3         portland, oregon, usa  32.0     19-35  \n",
       "4     cary, north carolina, usa  32.0     19-35  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge top_5_recommendations_df with users_df, drop location_idx and age_group_idx\n",
    "\n",
    "top_5_recommendations_users = pd.merge(top_5_recommendations_df, users_df.drop(columns=['location_idx', 'age_group_idx']), on='user_idx', how='left')\n",
    "top_5_recommendations_users.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7fa0016a911d70e86532c5706c9b4690ef8aee26a1d06018a1e37e463667ff8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
