{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkNAZvtNQ6R"
      },
      "source": [
        "# Recommending Books using LightGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxoenua1-u5r",
        "outputId": "2718b918-3398-4e59-d95f-f028db2a5cb1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim, Tensor\n",
        "import torch.sparse as sparse\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn import LGConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "11.8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
        "print(torch.version.cuda)         # Should print the CUDA version PyTorch is built with\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read in the raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\aimer\\AppData\\Local\\Temp\\ipykernel_2608\\1876496731.py:15: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  items_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n"
          ]
        }
      ],
      "source": [
        "users_df = pd.read_csv('data/BX-Users.csv', sep=';', encoding='latin-1')\n",
        "# rename 'Location' and 'Age' to lowercase\n",
        "users_df.rename(columns={'Location': 'location', 'Age': 'age'}, inplace=True)\n",
        "# Example age bins\n",
        "bins = [0, 18, 35, 55, 75, float('inf')]\n",
        "labels = ['0-18', '19-35', '36-55', '56-75', '76+']\n",
        "\n",
        "users_df['age'].fillna(users_df['age'].median(), inplace=True)\n",
        "\n",
        "users_df['age_group'] = pd.cut(users_df['age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# rename 'User-ID' to 'user_id' \n",
        "users_df.rename(columns={'User-ID': 'user_id'}, inplace=True)\n",
        "\n",
        "items_df = pd.read_csv('data/BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
        "# rename 'Book-Title' to 'title', 'Book-Author' to 'author'\n",
        "items_df.rename(columns={'Book-Title': 'title', 'Book-Author': 'author'}, inplace=True)\n",
        "# rename 'ISBN' to 'item_id'\n",
        "items_df.rename(columns={'ISBN': 'item_id'}, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>Year-Of-Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Image-URL-S</th>\n",
              "      <th>Image-URL-M</th>\n",
              "      <th>Image-URL-L</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0195153448</td>\n",
              "      <td>Classical Mythology</td>\n",
              "      <td>Mark P. O. Morford</td>\n",
              "      <td>2002</td>\n",
              "      <td>Oxford University Press</td>\n",
              "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002005018</td>\n",
              "      <td>Clara Callan</td>\n",
              "      <td>Richard Bruce Wright</td>\n",
              "      <td>2001</td>\n",
              "      <td>HarperFlamingo Canada</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0060973129</td>\n",
              "      <td>Decision in Normandy</td>\n",
              "      <td>Carlo D'Este</td>\n",
              "      <td>1991</td>\n",
              "      <td>HarperPerennial</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0374157065</td>\n",
              "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
              "      <td>Gina Bari Kolata</td>\n",
              "      <td>1999</td>\n",
              "      <td>Farrar Straus Giroux</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0393045218</td>\n",
              "      <td>The Mummies of Urumchi</td>\n",
              "      <td>E. J. W. Barber</td>\n",
              "      <td>1999</td>\n",
              "      <td>W. W. Norton &amp;amp; Company</td>\n",
              "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      item_id                                              title  \\\n",
              "0  0195153448                                Classical Mythology   \n",
              "1  0002005018                                       Clara Callan   \n",
              "2  0060973129                               Decision in Normandy   \n",
              "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
              "4  0393045218                             The Mummies of Urumchi   \n",
              "\n",
              "                 author Year-Of-Publication                   Publisher  \\\n",
              "0    Mark P. O. Morford                2002     Oxford University Press   \n",
              "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
              "2          Carlo D'Este                1991             HarperPerennial   \n",
              "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
              "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
              "\n",
              "                                         Image-URL-S  \\\n",
              "0  http://images.amazon.com/images/P/0195153448.0...   \n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "4  http://images.amazon.com/images/P/0393045218.0...   \n",
              "\n",
              "                                         Image-URL-M  \\\n",
              "0  http://images.amazon.com/images/P/0195153448.0...   \n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "4  http://images.amazon.com/images/P/0393045218.0...   \n",
              "\n",
              "                                         Image-URL-L  \n",
              "0  http://images.amazon.com/images/P/0195153448.0...  \n",
              "1  http://images.amazon.com/images/P/0002005018.0...  \n",
              "2  http://images.amazon.com/images/P/0060973129.0...  \n",
              "3  http://images.amazon.com/images/P/0374157065.0...  \n",
              "4  http://images.amazon.com/images/P/0393045218.0...  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "items_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>location</th>\n",
              "      <th>age</th>\n",
              "      <th>age_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>nyc, new york, usa</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>stockton, california, usa</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19-35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>moscow, yukon territory, russia</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>porto, v.n.gaia, portugal</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>farnborough, hants, united kingdom</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id                            location   age age_group\n",
              "0        1                  nyc, new york, usa  32.0     19-35\n",
              "1        2           stockton, california, usa  18.0     19-35\n",
              "2        3     moscow, yukon territory, russia  32.0     19-35\n",
              "3        4           porto, v.n.gaia, portugal  17.0      0-18\n",
              "4        5  farnborough, hants, united kingdom  32.0     19-35"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>Year-Of-Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Image-URL-S</th>\n",
              "      <th>Image-URL-M</th>\n",
              "      <th>Image-URL-L</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0195153448</td>\n",
              "      <td>Classical Mythology</td>\n",
              "      <td>Mark P. O. Morford</td>\n",
              "      <td>2002</td>\n",
              "      <td>Oxford University Press</td>\n",
              "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002005018</td>\n",
              "      <td>Clara Callan</td>\n",
              "      <td>Richard Bruce Wright</td>\n",
              "      <td>2001</td>\n",
              "      <td>HarperFlamingo Canada</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0060973129</td>\n",
              "      <td>Decision in Normandy</td>\n",
              "      <td>Carlo D'Este</td>\n",
              "      <td>1991</td>\n",
              "      <td>HarperPerennial</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0374157065</td>\n",
              "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
              "      <td>Gina Bari Kolata</td>\n",
              "      <td>1999</td>\n",
              "      <td>Farrar Straus Giroux</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0393045218</td>\n",
              "      <td>The Mummies of Urumchi</td>\n",
              "      <td>E. J. W. Barber</td>\n",
              "      <td>1999</td>\n",
              "      <td>W. W. Norton &amp;amp; Company</td>\n",
              "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      item_id                                              title  \\\n",
              "0  0195153448                                Classical Mythology   \n",
              "1  0002005018                                       Clara Callan   \n",
              "2  0060973129                               Decision in Normandy   \n",
              "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
              "4  0393045218                             The Mummies of Urumchi   \n",
              "\n",
              "                 author Year-Of-Publication                   Publisher  \\\n",
              "0    Mark P. O. Morford                2002     Oxford University Press   \n",
              "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
              "2          Carlo D'Este                1991             HarperPerennial   \n",
              "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
              "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
              "\n",
              "                                         Image-URL-S  \\\n",
              "0  http://images.amazon.com/images/P/0195153448.0...   \n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "4  http://images.amazon.com/images/P/0393045218.0...   \n",
              "\n",
              "                                         Image-URL-M  \\\n",
              "0  http://images.amazon.com/images/P/0195153448.0...   \n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "4  http://images.amazon.com/images/P/0393045218.0...   \n",
              "\n",
              "                                         Image-URL-L  \n",
              "0  http://images.amazon.com/images/P/0195153448.0...  \n",
              "1  http://images.amazon.com/images/P/0002005018.0...  \n",
              "2  http://images.amazon.com/images/P/0060973129.0...  \n",
              "3  http://images.amazon.com/images/P/0374157065.0...  \n",
              "4  http://images.amazon.com/images/P/0393045218.0...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "items_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(271360, 8)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "items_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# delete rows with missing values\n",
        "items_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(271353, 8)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "items_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>276725</td>\n",
              "      <td>034545104X</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>276726</td>\n",
              "      <td>0155061224</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>276727</td>\n",
              "      <td>0446520802</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>276729</td>\n",
              "      <td>052165615X</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>276729</td>\n",
              "      <td>0521795028</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id     item_id  rating\n",
              "0   276725  034545104X       0\n",
              "1   276726  0155061224       5\n",
              "2   276727  0446520802       0\n",
              "3   276729  052165615X       3\n",
              "4   276729  0521795028       6"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_df = pd.read_csv('data/BX-Book-Ratings.csv', sep=';', encoding='latin-1')  \n",
        "# rename 'User-ID' to 'user_id', 'Book-Rating' to 'rating', 'ISBN' to 'item_id'\n",
        "ratings_df.rename(columns={'User-ID': 'user_id', 'Book-Rating': 'rating', 'ISBN': 'item_id'}, inplace=True)\n",
        "ratings_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1031128, 3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Preprocessing\n",
        "ratings_df = ratings_df.loc[ratings_df['item_id'].isin(items_df['item_id'].unique()) & ratings_df['user_id'].isin(users_df['user_id'].unique())]\n",
        "\n",
        "print(ratings_df.shape)\n",
        "# # Keep the 100k highest ratings\n",
        "ratings_df = ratings_df[ratings_df['rating'] >= 8].iloc[:100000]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# subsert users_df where user_id is in ratings_df\n",
        "users_df = users_df[users_df['user_id'].isin(ratings_df['user_id'].unique())]\n",
        "# subsert items_df where item_id is in ratings_df\n",
        "items_df = items_df[items_df['item_id'].isin(ratings_df['item_id'].unique())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(19694, 4)\n",
            "(56946, 8)\n"
          ]
        }
      ],
      "source": [
        "print(users_df.shape)\n",
        "print(items_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 19694 entries, 11 to 278853\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype   \n",
            "---  ------     --------------  -----   \n",
            " 0   user_id    19694 non-null  int64   \n",
            " 1   location   19694 non-null  object  \n",
            " 2   age        19694 non-null  float64 \n",
            " 3   age_group  19694 non-null  category\n",
            " 4   user_idx   19694 non-null  int64   \n",
            "dtypes: category(1), float64(1), int64(2), object(1)\n",
            "memory usage: 788.7+ KB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create mappings\n",
        "user_mapping = {userid: i for i, userid in enumerate(users_df['user_id'].unique())}\n",
        "item_mapping = {isbn: i for i, isbn in enumerate(items_df['item_id'].unique())}\n",
        "\n",
        "# Count users and items\n",
        "num_users = len(user_mapping)\n",
        "num_items = len(item_mapping)\n",
        "num_total = num_users + num_items\n",
        "\n",
        "# Map user and item indices\n",
        "users_df['user_idx'] = users_df['user_id'].map(user_mapping)\n",
        "items_df['item_idx'] = items_df['item_id'].map(item_mapping)\n",
        "ratings_df['user_idx'] = ratings_df['user_id'].map(user_mapping)\n",
        "ratings_df['item_idx'] = ratings_df['item_id'].map(item_mapping)\n",
        "\n",
        "# Merge the user and item features with the ratings\n",
        "merged_df = ratings_df.merge(users_df, on='user_id').merge(items_df, on='item_id')\n",
        "\n",
        "users_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_df.item_idx.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>Year-Of-Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Image-URL-S</th>\n",
              "      <th>Image-URL-M</th>\n",
              "      <th>Image-URL-L</th>\n",
              "      <th>item_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002005018</td>\n",
              "      <td>Clara Callan</td>\n",
              "      <td>Richard Bruce Wright</td>\n",
              "      <td>2001</td>\n",
              "      <td>HarperFlamingo Canada</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0060973129</td>\n",
              "      <td>Decision in Normandy</td>\n",
              "      <td>Carlo D'Este</td>\n",
              "      <td>1991</td>\n",
              "      <td>HarperPerennial</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0374157065</td>\n",
              "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
              "      <td>Gina Bari Kolata</td>\n",
              "      <td>1999</td>\n",
              "      <td>Farrar Straus Giroux</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0399135782</td>\n",
              "      <td>The Kitchen God's Wife</td>\n",
              "      <td>Amy Tan</td>\n",
              "      <td>1991</td>\n",
              "      <td>Putnam Pub Group</td>\n",
              "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0425176428</td>\n",
              "      <td>What If?: The World's Foremost Military Histor...</td>\n",
              "      <td>Robert Cowley</td>\n",
              "      <td>2000</td>\n",
              "      <td>Berkley Publishing Group</td>\n",
              "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      item_id                                              title  \\\n",
              "1  0002005018                                       Clara Callan   \n",
              "2  0060973129                               Decision in Normandy   \n",
              "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
              "5  0399135782                             The Kitchen God's Wife   \n",
              "6  0425176428  What If?: The World's Foremost Military Histor...   \n",
              "\n",
              "                 author Year-Of-Publication                 Publisher  \\\n",
              "1  Richard Bruce Wright                2001     HarperFlamingo Canada   \n",
              "2          Carlo D'Este                1991           HarperPerennial   \n",
              "3      Gina Bari Kolata                1999      Farrar Straus Giroux   \n",
              "5               Amy Tan                1991          Putnam Pub Group   \n",
              "6         Robert Cowley                2000  Berkley Publishing Group   \n",
              "\n",
              "                                         Image-URL-S  \\\n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "5  http://images.amazon.com/images/P/0399135782.0...   \n",
              "6  http://images.amazon.com/images/P/0425176428.0...   \n",
              "\n",
              "                                         Image-URL-M  \\\n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "5  http://images.amazon.com/images/P/0399135782.0...   \n",
              "6  http://images.amazon.com/images/P/0425176428.0...   \n",
              "\n",
              "                                         Image-URL-L  item_idx  \n",
              "1  http://images.amazon.com/images/P/0002005018.0...         0  \n",
              "2  http://images.amazon.com/images/P/0060973129.0...         1  \n",
              "3  http://images.amazon.com/images/P/0374157065.0...         2  \n",
              "5  http://images.amazon.com/images/P/0399135782.0...         3  \n",
              "6  http://images.amazon.com/images/P/0425176428.0...         4  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "items_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing the dataset: transforming the user features and item features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fill missing values of locations, age_group, subject, author with 'unknown'\n",
        "def fillna_category(df, column):\n",
        "    df[column] = df[column].astype('category')\n",
        "    df[column].cat.add_categories('unknown')\n",
        "    df[column].fillna('unknown', inplace=True)\n",
        "\n",
        "# check if there are any missing values\n",
        "items_df.isna().sum()\n",
        "\n",
        "# delete rows with missing values in 'title' and 'author'\n",
        "items_df.dropna(subset=['title', 'author'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Function to map categories to indices\n",
        "def map_categories(df, column):\n",
        "    unique_values = df[column].unique()\n",
        "    value_to_idx = {value: idx for idx, value in enumerate(unique_values)}\n",
        "    return df[column].map(value_to_idx), len(unique_values)\n",
        "\n",
        "# Map each categorical feature\n",
        "users_df['location_idx'], num_locations = map_categories(users_df, 'location')\n",
        "users_df['age_group_idx'], num_age_groups = map_categories(users_df, 'age_group')\n",
        "items_df['subject_idx'], num_subjects = map_categories(items_df, 'title')\n",
        "items_df['author_idx'], num_authors = map_categories(items_df, 'author')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Input data for the Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert indices to tensors\n",
        "user_location_indices = torch.tensor(users_df['location_idx'].values, dtype=torch.long)\n",
        "user_age_group_indices = torch.tensor(users_df['age_group_idx'].values, dtype=torch.long)\n",
        "item_subject_indices = torch.tensor(items_df['subject_idx'].values, dtype=torch.long)\n",
        "item_author_indices = torch.tensor(items_df['author_idx'].values, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Edge Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # Tensors for user and item indices\n",
        "# user_indices = torch.tensor(merged_df['user_idx'].values, dtype=torch.long)\n",
        "# item_indices = torch.tensor(merged_df['item_idx'].values, dtype=torch.long)\n",
        "\n",
        "\n",
        "# # Tensor for ratings\n",
        "# ratings = torch.tensor(merged_df['rating'].values, dtype=torch.float)\n",
        "\n",
        "# # ratings = torch.tensor(merged_df['rating'].values, dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>location</th>\n",
              "      <th>age</th>\n",
              "      <th>age_group</th>\n",
              "      <th>user_idx</th>\n",
              "      <th>location_idx</th>\n",
              "      <th>age_group_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>fort bragg, california, usa</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>albuquerque, new mexico, usa</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>bellevue, washington, usa</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>portland, oregon, usa</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>cary, north carolina, usa</td>\n",
              "      <td>32.0</td>\n",
              "      <td>19-35</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id                      location   age age_group  user_idx  \\\n",
              "11       12   fort bragg, california, usa  32.0     19-35         0   \n",
              "15       16  albuquerque, new mexico, usa  32.0     19-35         1   \n",
              "25       26     bellevue, washington, usa  32.0     19-35         2   \n",
              "31       32         portland, oregon, usa  32.0     19-35         3   \n",
              "38       39     cary, north carolina, usa  32.0     19-35         4   \n",
              "\n",
              "    location_idx age_group_idx  \n",
              "11             0             0  \n",
              "15             1             0  \n",
              "25             2             0  \n",
              "31             3             0  \n",
              "38             4             0  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>Year-Of-Publication</th>\n",
              "      <th>Publisher</th>\n",
              "      <th>Image-URL-S</th>\n",
              "      <th>Image-URL-M</th>\n",
              "      <th>Image-URL-L</th>\n",
              "      <th>item_idx</th>\n",
              "      <th>subject_idx</th>\n",
              "      <th>author_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002005018</td>\n",
              "      <td>Clara Callan</td>\n",
              "      <td>Richard Bruce Wright</td>\n",
              "      <td>2001</td>\n",
              "      <td>HarperFlamingo Canada</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0060973129</td>\n",
              "      <td>Decision in Normandy</td>\n",
              "      <td>Carlo D'Este</td>\n",
              "      <td>1991</td>\n",
              "      <td>HarperPerennial</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0374157065</td>\n",
              "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
              "      <td>Gina Bari Kolata</td>\n",
              "      <td>1999</td>\n",
              "      <td>Farrar Straus Giroux</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0399135782</td>\n",
              "      <td>The Kitchen God's Wife</td>\n",
              "      <td>Amy Tan</td>\n",
              "      <td>1991</td>\n",
              "      <td>Putnam Pub Group</td>\n",
              "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0425176428</td>\n",
              "      <td>What If?: The World's Foremost Military Histor...</td>\n",
              "      <td>Robert Cowley</td>\n",
              "      <td>2000</td>\n",
              "      <td>Berkley Publishing Group</td>\n",
              "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
              "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      item_id                                              title  \\\n",
              "1  0002005018                                       Clara Callan   \n",
              "2  0060973129                               Decision in Normandy   \n",
              "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
              "5  0399135782                             The Kitchen God's Wife   \n",
              "6  0425176428  What If?: The World's Foremost Military Histor...   \n",
              "\n",
              "                 author Year-Of-Publication                 Publisher  \\\n",
              "1  Richard Bruce Wright                2001     HarperFlamingo Canada   \n",
              "2          Carlo D'Este                1991           HarperPerennial   \n",
              "3      Gina Bari Kolata                1999      Farrar Straus Giroux   \n",
              "5               Amy Tan                1991          Putnam Pub Group   \n",
              "6         Robert Cowley                2000  Berkley Publishing Group   \n",
              "\n",
              "                                         Image-URL-S  \\\n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "5  http://images.amazon.com/images/P/0399135782.0...   \n",
              "6  http://images.amazon.com/images/P/0425176428.0...   \n",
              "\n",
              "                                         Image-URL-M  \\\n",
              "1  http://images.amazon.com/images/P/0002005018.0...   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...   \n",
              "5  http://images.amazon.com/images/P/0399135782.0...   \n",
              "6  http://images.amazon.com/images/P/0425176428.0...   \n",
              "\n",
              "                                         Image-URL-L  item_idx  subject_idx  \\\n",
              "1  http://images.amazon.com/images/P/0002005018.0...         0            0   \n",
              "2  http://images.amazon.com/images/P/0060973129.0...         1            1   \n",
              "3  http://images.amazon.com/images/P/0374157065.0...         2            2   \n",
              "5  http://images.amazon.com/images/P/0399135782.0...         3            3   \n",
              "6  http://images.amazon.com/images/P/0425176428.0...         4            4   \n",
              "\n",
              "   author_idx  \n",
              "1           0  \n",
              "2           1  \n",
              "3           2  \n",
              "5           3  \n",
              "6           4  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "items_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>user_idx</th>\n",
              "      <th>item_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>276747</td>\n",
              "      <td>0060517794</td>\n",
              "      <td>9</td>\n",
              "      <td>19324</td>\n",
              "      <td>3147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>276747</td>\n",
              "      <td>0671537458</td>\n",
              "      <td>9</td>\n",
              "      <td>19324</td>\n",
              "      <td>1258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>276747</td>\n",
              "      <td>0679776818</td>\n",
              "      <td>8</td>\n",
              "      <td>19324</td>\n",
              "      <td>4053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>276751</td>\n",
              "      <td>3596218098</td>\n",
              "      <td>8</td>\n",
              "      <td>19325</td>\n",
              "      <td>18749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>276754</td>\n",
              "      <td>0684867621</td>\n",
              "      <td>8</td>\n",
              "      <td>19326</td>\n",
              "      <td>1346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user_id     item_id  rating  user_idx  item_idx\n",
              "16   276747  0060517794       9     19324      3147\n",
              "19   276747  0671537458       9     19324      1258\n",
              "20   276747  0679776818       8     19324      4053\n",
              "27   276751  3596218098       8     19325     18749\n",
              "28   276754  0684867621       8     19326      1346"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_df.item_idx.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# in ratings_df, exclude rows with item_idx < 0\n",
        "ratings_df = ratings_df[ratings_df['item_idx'] >= 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def create_adjacency_matrix(users_df, items_df, ratings_df):\n",
        "    # Basic data validation\n",
        "    if not all(col in users_df.columns for col in ['user_idx']) or \\\n",
        "       not all(col in items_df.columns for col in ['item_idx']) or \\\n",
        "       not all(col in ratings_df.columns for col in ['user_idx', 'item_idx']):\n",
        "        raise ValueError(\"Dataframes do not have the required columns\")\n",
        "\n",
        "    num_users = users_df['user_idx'].nunique()\n",
        "    num_items = items_df['item_idx'].nunique()\n",
        "\n",
        "    # Convert indices to tensor-friendly format\n",
        "    user_ids = ratings_df['user_idx'].values.astype(np.int64)\n",
        "    item_ids = ratings_df['item_idx'].values.astype(np.int64) + num_users\n",
        "\n",
        "    # Create edge index tensors\n",
        "    start_idx = torch.LongTensor([user_ids, item_ids])\n",
        "    end_idx = torch.LongTensor([item_ids, user_ids])\n",
        "\n",
        "    # Create values tensor\n",
        "    values = torch.FloatTensor([1] * 2 * len(ratings_df))\n",
        "\n",
        "    # Construct sparse adjacency matrix\n",
        "    adj_matrix = torch.sparse.FloatTensor(torch.cat([start_idx, end_idx], dim=1), values, torch.Size([num_users + num_items, num_users + num_items]))\n",
        "\n",
        "    # Normalize adjacency matrix\n",
        "    # Computing degree (sum of edges for each node)\n",
        "    deg = torch.sparse.sum(adj_matrix, dim=1).to_dense()\n",
        "\n",
        "    # Efficient normalization for user rows\n",
        "    indices = adj_matrix._indices()\n",
        "    values = adj_matrix._values()\n",
        "\n",
        "    for i in range(indices.size(1)):\n",
        "        row = indices[0, i]\n",
        "        if row < num_users:  # Normalize only user rows\n",
        "            values[i] /= deg[row]\n",
        "\n",
        "    # Reconstruct normalized adjacency matrix\n",
        "    norm_adj = torch.sparse.FloatTensor(indices, values, adj_matrix.size())\n",
        "\n",
        "    return norm_adj\n",
        "\n",
        "# Example usage\n",
        "adj_matrix = create_adjacency_matrix(users_df, items_df, ratings_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### split the train-validtion-test adj matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def split_sparse_tensor(adj_matrix, train_ratio=0.8, val_ratio=0.1):\n",
        "    # Extract the total number of users and items from the dimensions of the adjacency matrix\n",
        "    total_nodes = adj_matrix.size(0)\n",
        "    num_users = torch.max(adj_matrix._indices()[0]).item() + 1\n",
        "    num_items = total_nodes - num_users\n",
        "\n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    test_indices = []\n",
        "\n",
        "    for user in range(num_users):\n",
        "        # Filter items for this user\n",
        "        user_mask = adj_matrix._indices()[0] == user\n",
        "        user_items = adj_matrix._indices()[1][user_mask] - num_users  # Adjust item index\n",
        "\n",
        "        # Shuffle items\n",
        "        shuffled_indices = torch.randperm(user_items.size(0))\n",
        "        user_items = user_items[shuffled_indices]\n",
        "\n",
        "        # Split items\n",
        "        num_train = int(user_items.size(0) * train_ratio)\n",
        "        num_val = int(user_items.size(0) * val_ratio)\n",
        "\n",
        "        train_items = user_items[:num_train]\n",
        "        val_items = user_items[num_train:num_train + num_val]\n",
        "        test_items = user_items[num_train + num_val:]\n",
        "\n",
        "        # Add to indices lists\n",
        "        train_indices.append(torch.stack([torch.full_like(train_items, user), train_items + num_users], dim=0))\n",
        "        val_indices.append(torch.stack([torch.full_like(val_items, user), val_items + num_users], dim=0))\n",
        "        test_indices.append(torch.stack([torch.full_like(test_items, user), test_items + num_users], dim=0))\n",
        "\n",
        "    def create_sparse_tensor(indices_list):\n",
        "        all_indices = torch.cat(indices_list, dim=1)\n",
        "        values = torch.ones(all_indices.size(1))\n",
        "        return torch.sparse.FloatTensor(all_indices, values, adj_matrix.size())\n",
        "\n",
        "    train_adj_matrix = create_sparse_tensor(train_indices)\n",
        "    val_adj_matrix = create_sparse_tensor(val_indices)\n",
        "    test_adj_matrix = create_sparse_tensor(test_indices)\n",
        "\n",
        "    return train_adj_matrix, val_adj_matrix, test_adj_matrix\n",
        "\n",
        "# Example usage\n",
        "train_adj_matrix, val_adj_matrix, test_adj_matrix = split_sparse_tensor(adj_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[    0,     1,     2,  ..., 76637, 76638, 76639],\n",
              "                       [19704, 19706, 19711,  ..., 19222, 19222, 18920]]),\n",
              "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
              "       size=(76640, 76640), nnz=86674, layout=torch.sparse_coo)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_adj_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graph Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(56946, 11)\n",
            "56946\n"
          ]
        }
      ],
      "source": [
        "print(items_df.shape)\n",
        "print(items_df.item_idx.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class GraphDataLoader:\n",
        "    def __init__(self, adj_matrix, users_df, items_df, num_negatives=1, batch_size=1024, device='cuda'):\n",
        "        self.adj_matrix = adj_matrix.to(device)  # Move adjacency matrix to the specified device\n",
        "        self.num_negatives = num_negatives\n",
        "        self.batch_size = batch_size\n",
        "        self.num_users = users_df['user_idx'].nunique()\n",
        "        self.num_items = items_df['item_idx'].nunique()\n",
        "        self.device = device  # Store the device\n",
        "        self.negatives = self.precompute_negatives()\n",
        "\n",
        "    def precompute_negatives(self):\n",
        "        negatives = {}\n",
        "        for user in range(self.num_users):\n",
        "            user_row = self.adj_matrix[user].coalesce()\n",
        "            if user_row._nnz() > 0:\n",
        "                pos_items = user_row.indices()[0].cpu().numpy()  # Move to CPU for numpy compatibility\n",
        "                neg_items = np.setdiff1d(np.arange(self.num_items), pos_items)\n",
        "                negatives[user] = neg_items\n",
        "            else:\n",
        "                negatives[user] = np.arange(self.num_items)\n",
        "        return negatives\n",
        "\n",
        "    def generate_batch(self):\n",
        "        for batch_start in range(0, self.num_users, self.batch_size):\n",
        "            batch_users, batch_pos_items, batch_neg_items = [], [], []\n",
        "\n",
        "            for user in range(batch_start, min(batch_start + self.batch_size, self.num_users)):\n",
        "                user_row = self.adj_matrix[user].coalesce()\n",
        "                if user_row._nnz() > 0:\n",
        "                    pos_items = user_row.indices()[0].cpu().numpy()\n",
        "                    pos_item = np.random.choice(pos_items)\n",
        "                    neg_samples = np.random.choice(self.negatives[user], self.num_negatives, replace=False)\n",
        "\n",
        "                    batch_users.extend([user] * self.num_negatives)\n",
        "                    batch_pos_items.extend([pos_item] * self.num_negatives)\n",
        "                    batch_neg_items.extend(neg_samples)  # No offset added here\n",
        "\n",
        "            if batch_users:\n",
        "                yield torch.tensor(batch_users, dtype=torch.long, device=self.device), \\\n",
        "                      torch.tensor(batch_pos_items, dtype=torch.long, device=self.device), \\\n",
        "                      torch.tensor(batch_neg_items, dtype=torch.long, device=self.device)\n",
        "\n",
        "# Example usage\n",
        "# data_loader = GraphDataLoader(adj_matrix, users_df, items_df)\n",
        "# for batch in data_loader.generate_batch():\n",
        "#     # process the batch\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "## Implementing the LightGCN architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.sparse import mm as sparse_mm\n",
        "\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim, num_layers):\n",
        "        super(LightGCN, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Initialize user and item embeddings\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        # Initialization\n",
        "        nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
        "        nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
        "\n",
        "    def forward(self, user_indices, item_indices, adj_matrix):\n",
        "        # Ensure that user and item indices are within the valid range\n",
        "        assert user_indices.min() >= 0 and user_indices.max() < self.num_users, \"User indices out of range\"\n",
        "        assert item_indices.min() >= 0 and item_indices.max() < self.num_items, \"Item indices out of range\"\n",
        "\n",
        "        # Create initial embeddings\n",
        "        all_embeddings = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
        "\n",
        "        # List to hold all embeddings for each layer\n",
        "        all_user_embs = [self.user_embedding(user_indices)]\n",
        "        all_item_embs = [self.item_embedding(item_indices)]\n",
        "\n",
        "        # Perform graph convolutions\n",
        "        for _ in range(self.num_layers):\n",
        "            all_embeddings = sparse_mm(adj_matrix, all_embeddings)\n",
        "\n",
        "            user_emb = all_embeddings[:self.num_users]\n",
        "            item_emb = all_embeddings[self.num_users:]\n",
        "\n",
        "            all_user_embs.append(user_emb[user_indices])\n",
        "            all_item_embs.append(item_emb[item_indices])\n",
        "\n",
        "        # Compute final embeddings as the mean of all layers' embeddings\n",
        "        final_user_emb = torch.mean(torch.stack(all_user_embs), dim=0)\n",
        "        final_item_emb = torch.mean(torch.stack(all_item_embs), dim=0)\n",
        "\n",
        "        # Predict ratings by computing the dot product of user and item embeddings\n",
        "        scores = torch.sum(final_user_emb * final_item_emb, dim=1)\n",
        "\n",
        "        return scores\n",
        "\n",
        "# Example usage:\n",
        "# model = LightGCN(num_users=1000, num_items=500, embedding_dim=64, num_layers=3)\n",
        "# ... (setup data and training loop) ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, data_loader, epochs, optimizer, loss_fn, adj_matrix):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = 0  # Counter for the number of batches processed\n",
        "\n",
        "        for batch_data in data_loader.generate_batch():\n",
        "            users, pos_items, neg_items = batch_data\n",
        "            if users is None:\n",
        "                continue  # Skip the batch if it's empty\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Ensure tensors are on the GPU and adjust item indices\n",
        "            users = users.cuda()\n",
        "            pos_items = (pos_items - data_loader.num_users).cuda()  # Adjust positive item indices\n",
        "            neg_items = (neg_items - data_loader.num_users).cuda()  # Adjust negative item indices\n",
        "\n",
        "            # Positive and negative predictions\n",
        "            pos_scores = model(users, pos_items, adj_matrix.cuda())\n",
        "            neg_scores = model(users, neg_items, adj_matrix.cuda())\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(pos_scores, neg_scores)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1  # Increment batch counter\n",
        "\n",
        "        # Compute average loss\n",
        "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")\n",
        "\n",
        "# Example usage:\n",
        "# model = LightGCN(num_users, num_items, embedding_dim=64, num_layers=3).cuda()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "# loss_fn = bpr_loss  # or any other loss function you defined\n",
        "# data_loader = GraphDataLoader(adj_matrix, users_df, items_df, num_negatives=1, batch_size=64)\n",
        "# train(model, data_loader, epochs=10, optimizer, loss_fn, adj_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "def precision_at_k(targets, predictions, k=10):\n",
        "    top_k_preds = predictions.topk(k, dim=1).indices\n",
        "    relevant = targets.gather(1, top_k_preds)\n",
        "    precision = relevant.sum().float() / (k * targets.size(0))\n",
        "    return precision\n",
        "\n",
        "def recall_at_k(targets, predictions, k=10):\n",
        "    top_k_preds = predictions.topk(k, dim=1).indices\n",
        "    relevant = targets.gather(1, top_k_preds)\n",
        "    recall = relevant.sum().float() / targets.sum()\n",
        "    return recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    precision_sum, recall_sum = 0, 0\n",
        "    with torch.no_grad(): \n",
        "        for batch in data_loader:\n",
        "            users, items = batch\n",
        "            scores = model(users, items, adj_matrix)\n",
        "            targets = adj_matrix[users].to_dense()  # Convert to dense for simplicity\n",
        "\n",
        "            precision_sum += precision_at_k(targets, scores, k)\n",
        "            recall_sum += recall_at_k(targets, scores, k)\n",
        "    \n",
        "    precision = precision_sum / len(data_loader)\n",
        "    recall = recall_sum / len(data_loader)\n",
        "    return precision, recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "   \n",
        "# BPR Loss\n",
        "def bpr_loss(pos_scores, neg_scores):\n",
        "    return -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_adj_matrix, val_adj_matrix, test_adj_matrix = split_adj_matrix(adj_matrix)\n",
        "train_loader = GraphDataLoader(train_adj_matrix, users_df, items_df, num_negatives=1, batch_size=64)\n",
        "val_loader = GraphDataLoader(val_adj_matrix, users_df, items_df, num_negatives=1, batch_size=64)\n",
        "test_loader = GraphDataLoader(test_adj_matrix, users_df, items_df, num_negatives=1, batch_size=64)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "def train_and_validate(model, train_loader, val_loader, epochs, optimizer, loss_fn, adj_matrix, early_stopping_rounds=5, device='cuda'):\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_epochs = 0\n",
        "\n",
        "    model = model.to(device)\n",
        "    # adj_matrix = adj_matrix.to(device)\n",
        "    # train_loader = train_loader.to(device)\n",
        "    # val_loader = val_loader.to(device)\n",
        "    # model = model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        for users, pos_items, neg_items in train_loader.generate_batch():\n",
        "            # Move tensors to the specified device\n",
        "            users, pos_items, neg_items = users.to(device), pos_items.to(device), neg_items.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            pos_scores = model(users, pos_items, adj_matrix)\n",
        "            neg_scores = model(users, neg_items, adj_matrix)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(pos_scores, neg_scores)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "\n",
        "        avg_train_loss = total_train_loss / num_train_batches if num_train_batches > 0 else 0\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {avg_train_loss:.4f}\", end='')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        num_val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for users, pos_items, neg_items in val_loader.generate_batch():\n",
        "                # Move tensors to the specified device\n",
        "                users, pos_items, neg_items = users.to(device), pos_items.to(device), neg_items.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                pos_scores = model(users, pos_items, adj_matrix)\n",
        "                neg_scores = model(users, neg_items, adj_matrix)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_fn(pos_scores, neg_scores)\n",
        "\n",
        "                total_val_loss += loss.item()\n",
        "                num_val_batches += 1\n",
        "\n",
        "        avg_val_loss = total_val_loss / num_val_batches if num_val_batches > 0 else 0\n",
        "        print(f\" - Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            no_improvement_epochs = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), 'models/best_model.pth')\n",
        "        else:\n",
        "            no_improvement_epochs += 1\n",
        "            if no_improvement_epochs >= early_stopping_rounds:\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "                break\n",
        "\n",
        "# Load the best model after training is complete or early stopping is triggered\n",
        "# model.load_state_dict(torch.load('best_model.pth'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Item indices out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[122], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m adj_matrix \u001b[38;5;241m=\u001b[39m adj_matrix\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Corrected function call\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[121], line 26\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(model, train_loader, val_loader, epochs, optimizer, loss_fn, adj_matrix, early_stopping_rounds, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m pos_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43musers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m neg_scores \u001b[38;5;241m=\u001b[39m model(users, neg_items, adj_matrix)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\aimer\\.conda\\envs\\recommend\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\aimer\\.conda\\envs\\recommend\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[117], line 25\u001b[0m, in \u001b[0;36mLightGCN.forward\u001b[1;34m(self, user_indices, item_indices, adj_matrix)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_indices, item_indices, adj_matrix):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Ensure that user and item indices are within the valid range\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m user_indices\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m user_indices\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_users, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser indices out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m item_indices\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m item_indices\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_items, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem indices out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Create initial embeddings\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embedding\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embedding\u001b[38;5;241m.\u001b[39mweight], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[1;31mAssertionError\u001b[0m: Item indices out of range"
          ]
        }
      ],
      "source": [
        "# Define the model and optimizer with L2 regularization\n",
        "device = 'cuda'\n",
        "model = LightGCN(num_users, num_items, embedding_dim=64, num_layers=3).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "loss_fn = bpr_loss  # Define your loss function\n",
        "# data_loader = GraphDataLoader(adj_matrix, users_df, items_df, num_negatives=1, batch_size=64)\n",
        "adj_matrix = adj_matrix.to(device)\n",
        "# Corrected function call\n",
        "train_and_validate(model, train_loader, val_loader, 10, optimizer, loss_fn, adj_matrix, early_stopping_rounds=5, device='cuda')\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "train(model, data_loader, epochs=10, optimizer=optimizer, loss_fn=bpr_loss)\n",
        "\n",
        "# Evaluate the model\n",
        "# Define an appropriate metric function depending on your task\n",
        "print(\"Evaluation Metric:\", evaluate_model(model, data_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'models/book_recommend_lightgcn_features_model_epochs30.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "outputs": [],
      "source": [
        "K = 20\n",
        "LAMBDA = 1e-6\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "num_user_features = user_features.shape[1]-1\n",
        "print(num_user_features)\n",
        "num_item_features = item_features.shape[1]-1\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# model = LightGCN(num_users, num_items, num_user_features, num_item_features, num_layers=4, dim_h=64)\n",
        "model = LightGCN(num_users, num_items, num_user_features, num_item_features)\n",
        "\n",
        "model = model.to(device)\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "user_features = user_features.to(device)\n",
        "\n",
        "# check the dimensions of the user_features tensor\n",
        "print(user_features.shape)\n",
        "# \n",
        "item_features = item_features.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "d2e1739f-8002-4a1b-d98a-3b27fb6cc04b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "n_batch = int(len(train_index) / BATCH_SIZE)\n",
        "\n",
        "for epoch in range(31):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    total_train_loss = 0  # To accumulate loss over the epoch\n",
        "\n",
        "    for _ in range(n_batch):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        emb_users_final, emb_users, emb_items_final, emb_items = model(\n",
        "            train_edge_index, user_features, item_features)\n",
        "\n",
        "        # Sample a mini-batch\n",
        "        user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(train_edge_index)\n",
        "\n",
        "        # Select the corresponding embeddings\n",
        "        emb_users_final_batch = emb_users_final[user_indices]\n",
        "        emb_users_batch = emb_users[user_indices]\n",
        "        emb_pos_items_final_batch = emb_items_final[pos_item_indices]\n",
        "        emb_pos_items_batch = emb_items[pos_item_indices]\n",
        "        emb_neg_items_final_batch = emb_items_final[neg_item_indices]\n",
        "        emb_neg_items_batch = emb_items[neg_item_indices]\n",
        "\n",
        "        # Compute loss\n",
        "        train_loss = bpr_loss(emb_users_final_batch, emb_users_batch, \n",
        "                              emb_pos_items_final_batch, emb_pos_items_batch, \n",
        "                              emb_neg_items_final_batch, emb_neg_items_batch)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += train_loss.item()\n",
        "\n",
        "    # Average training loss for the epoch\n",
        "    avg_train_loss = total_train_loss / n_batch\n",
        "\n",
        "    # Validation step\n",
        "    if epoch % 5 == 0:\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            val_loss, recall, ndcg = test(model, val_edge_index, [train_edge_index])\n",
        "            print(f\"Epoch {epoch} | Train loss: {avg_train_loss:.5f} | Val loss: {val_loss:.5f} | Val recall@{K}: {recall:.5f} | Val ndcg@{K}: {ndcg:.5f}\")\n",
        "\n",
        "# Save the model after training is complete\n",
        "model_path = 'models/book_recommend_lightgcn_features_model_epochs30.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved at {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Max index in user_features:\", user_features[:, 0].max().item())\n",
        "print(\"Number of users:\", num_users)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6UjCTMQ_N5e"
      },
      "outputs": [],
      "source": [
        "test_loss, test_recall, test_ndcg = test(model, test_edge_index.to(device), [train_edge_index, val_edge_index])\n",
        "\n",
        "print(f\"Test loss: {test_loss:.5f} | Test recall@{K}: {test_recall:.5f} | Test ndcg@{K}: {test_ndcg:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming 'model' is your GNN model\n",
        "torch.save(model, 'models/book_recommend_lightgcn_features_model_epochs30.pth')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "## Recommending books for a particular user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = torch.load('models/book_recommend_lightgcn_model_epochs30.pth')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "outputs": [],
      "source": [
        "bookid_title = pd.Series(items_df['title'].values, index=items_df.ISBN).to_dict()\n",
        "bookid_author = pd.Series(items_df['author'].values, index=items_df.ISBN).to_dict()\n",
        "user_pos_items = get_user_items(edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend(user_id, num_recs):\n",
        "    user = user_mapping.get(user_id)\n",
        "    print(\"user_idx is \", user)\n",
        "    if user is None:\n",
        "        print(f\"User ID {user_id} not found.\")\n",
        "        return [], []\n",
        "\n",
        "    emb_user = model.emb_users.weight[user]\n",
        "    ratings = model.emb_items.weight @ emb_user\n",
        "\n",
        "    values, indices = torch.topk(ratings, k=100)\n",
        "\n",
        "    ids = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n",
        "    titles = [bookid_title[id] for id in item_isbns]\n",
        "    authors = [bookid_author[id] for id in item_isbns]\n",
        "\n",
        "    print(f'Favorite books from user n°{user_id}:')\n",
        "    for i in range(len(item_isbns)):\n",
        "        print(f'- {titles[i]}, by {authors[i]}')\n",
        "\n",
        "    ids = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    item_isbns = [list(item_mapping.keys())[list(item_mapping.values()).index(book)] for book in ids]\n",
        "    titles = [bookid_title[id] for id in item_isbns]\n",
        "    authors = [bookid_author[id] for id in item_isbns]\n",
        "\n",
        "    print(f'\\nRecommended books for user n°{user_id}')\n",
        "    for i in range(num_recs):\n",
        "        print(f'- {titles[i]}, by {authors[i]}') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommend(2084, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "outputs": [],
      "source": [
        "recommend(3305, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommend(277427, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSFgwnaecWBw"
      },
      "outputs": [],
      "source": [
        "recommend(277427, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommend(2084, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommend(1519, 5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gnnbook",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7fa0016a911d70e86532c5706c9b4690ef8aee26a1d06018a1e37e463667ff8c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
